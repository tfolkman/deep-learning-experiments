{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/tyler/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from comet_ml import Experiment\n",
    "\n",
    "import os\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "from gym.spaces.box import Box\n",
    "\n",
    "from baselines import bench\n",
    "from baselines.common.atari_wrappers import make_atari, wrap_deepmind\n",
    "from baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_envs = 8\n",
    "lr               = 2.5e-4\n",
    "num_steps        = 128\n",
    "mini_batch_size  = 32\n",
    "ppo_epochs       = 4\n",
    "save_every_update = 50\n",
    "gamma = 0.99\n",
    "tau = 0.95\n",
    "critic_weight = 1.0\n",
    "entropy_weight = 0.01\n",
    "clip_param = 0.1\n",
    "max_frames  = 5000\n",
    "\n",
    "\n",
    "render = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(env_id, seed, rank):\n",
    "    def _thunk():\n",
    "        if env_id.startswith(\"dm\"):\n",
    "            _, domain, task = env_id.split('.')\n",
    "            env = dm_control2gym.make(domain_name=domain, task_name=task)\n",
    "        else:\n",
    "            env = gym.make(env_id)\n",
    "        is_atari = hasattr(gym.envs, 'atari') and isinstance(\n",
    "            env.unwrapped, gym.envs.atari.atari_env.AtariEnv)\n",
    "        if is_atari:\n",
    "            # Does some pre-processing that affects pong\n",
    "            # 1) Samples initial states by taking random number of no-ops\n",
    "            #    on reset (at most 30)\n",
    "            # 2) Returns only every 4th frame\n",
    "            env = make_atari(env_id)\n",
    "        env.seed(seed + rank)\n",
    "\n",
    "\n",
    "        if is_atari:\n",
    "            # Does some pre-processing that affects pong\n",
    "            # 1) Make end-of-life == end-of-episode, but only reset on true game over\n",
    "            # 2) Warp frames to 84x84\n",
    "            # 3) Stack 4 frames\n",
    "            # 4) Scale the image by dividing by 255\n",
    "            env = wrap_deepmind(env, frame_stack=True, scale=True)\n",
    "\n",
    "        return env\n",
    "\n",
    "    return _thunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-6:\n",
      "Process Process-7:\n",
      "Process Process-2:\n",
      "Process Process-8:\n",
      "Traceback (most recent call last):\n",
      "Process Process-5:\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "Process Process-3:\n",
      "Process Process-4:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from common.multiprocessing_env import SubprocVecEnv\n",
    "\n",
    "env_name = \"CartPole-v0\"\n",
    "seed = 42\n",
    "\n",
    "\n",
    "envs = [make_env(env_name, seed, i)\n",
    "        for i in range(num_envs)]\n",
    "\n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_normc_(weight, gain=1):\n",
    "    weight.normal_(0, 1)\n",
    "    weight *= gain / torch.sqrt(weight.pow(2).sum(1, keepdim=True))\n",
    "    \n",
    "def init(module, weight_init, bias_init, gain=1):\n",
    "    weight_init(module.weight.data, gain=gain)\n",
    "    bias_init(module.bias.data)\n",
    "    return module\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        init_ = lambda m: init(m,\n",
    "              init_normc_,\n",
    "              lambda x: nn.init.constant_(x, 0))\n",
    "\n",
    "        self.actor = nn.Sequential(\n",
    "            init_(nn.Linear(num_inputs, 64)),\n",
    "            nn.Tanh(),\n",
    "            init_(nn.Linear(64, 64)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.critic = nn.Sequential(\n",
    "            init_(nn.Linear(num_inputs, 64)),\n",
    "            nn.Tanh(),\n",
    "            init_(nn.Linear(64, 64)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.critic_linear = init_(nn.Linear(64, 1))\n",
    "        self.actor_linear   = init_(nn.Linear(64, num_outputs))\n",
    "                         \n",
    "    def forward(self, x):\n",
    "        value = self.critic_linear(self.critic(x))\n",
    "        softs = F.softmax(self.actor_linear(self.actor(x)), dim=1)\n",
    "        dist = Categorical(softs)\n",
    "        return dist, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "    \n",
    "def test_env(vis=False):\n",
    "    state = env.reset()\n",
    "    if vis: env.render()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        next_state, reward, done, _ = env.step(dist.sample().cpu().numpy()[0])\n",
    "        state = next_state\n",
    "        if vis: env.render()\n",
    "        total_reward += reward\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gae(next_value, rewards, masks, values, gamma=gamma, tau=tau):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outputs = envs.action_space.n\n",
    "\n",
    "model = ActorCritic(4, num_outputs).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, eps=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx    = 0\n",
    "test_rewards = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important\n",
    "\n",
    "With GAE: GAE advantage just used for actor loss. Discounted returns used for critic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## grab random values for each batch\n",
    "def ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantage, values):\n",
    "    batch_size = states.size(0)\n",
    "    sampler = BatchSampler(SubsetRandomSampler(range(batch_size)), \n",
    "                           mini_batch_size, \n",
    "                           drop_last=False)\n",
    "    for rand_ids in sampler:\n",
    "        yield states[rand_ids, :], actions[rand_ids, :], log_probs[rand_ids, :], returns[rand_ids, :], advantage[rand_ids, :], values[rand_ids, :]\n",
    "        \n",
    "        \n",
    "def ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, values, clip_param=clip_param):\n",
    "    for _ in range(ppo_epochs):\n",
    "        for s, act, lp, r, adv, v in ppo_iter(mini_batch_size, states, actions, log_probs,\n",
    "                                                                       returns, advantages, values):\n",
    "            \n",
    "            \n",
    "            new_dist, new_value = model(s)\n",
    "            new_entropy = new_dist.entropy().mean()\n",
    "            new_log_prob = new_dist.log_prob(act)\n",
    "            ratio = torch.exp(new_log_prob - lp)\n",
    "            surr1 = ratio * adv\n",
    "            surr2 = torch.clamp(ratio, 1.0 - clip_param, 1.0 + clip_param) * adv\n",
    "            actor_loss = - torch.min(surr1, surr2).mean()\n",
    "            #actor_loss = -(lp * adv.detach()).mean()\n",
    "            critic_loss = F.mse_loss(r,new_value)\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = (actor_loss + critic_weight * critic_loss - entropy_weight * new_entropy)\n",
    "            loss.backward(retain_graph=True)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "    return actor_loss, critic_loss, -new_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAE/CAYAAACNR5LeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-40997486b5b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframe_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msave_every_update\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mtest_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_rewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-40997486b5b0>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframe_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msave_every_update\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mtest_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_rewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-1b321ea5f7a9>\u001b[0m in \u001b[0;36mtest_env\u001b[0;34m(vis)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tyler/anaconda3/lib/python3.6/site-packages/torch/distributions/categorical.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mprobs_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_events\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mprobs_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_events\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "state = envs.reset()\n",
    "update_iter = 0\n",
    "test_rewards\n",
    "\n",
    "while frame_idx < max_frames:\n",
    "    log_probs = []\n",
    "    values = []\n",
    "    rewards = []\n",
    "    masks = []\n",
    "    states = []\n",
    "    actions = []\n",
    "\n",
    "    \n",
    "    for step_index in range(num_steps):\n",
    "        # state is 16 x 4 because 16 envs\n",
    "        state = torch.FloatTensor(state).to(device)\n",
    "        states.append(state)\n",
    "        # dist and value each have 16 for all envs\n",
    "        dist, value = model(state)\n",
    "        \n",
    "        # have 16 actions\n",
    "        action = dist.sample()\n",
    "        actions.append(action)\n",
    "        next_state, reward, done, _ = envs.step(action.cpu().numpy())\n",
    "        \n",
    "        log_prob = dist.log_prob(action)\n",
    "\n",
    "        log_probs.append(log_prob)\n",
    "        values.append(value)\n",
    "        # there are 16 rewards. Need to make it 16x1. Same for masks\n",
    "        rewards.append(torch.FloatTensor(reward).unsqueeze(1).to(device))\n",
    "        masks.append(torch.FloatTensor(1 - done).unsqueeze(1).to(device))\n",
    "                \n",
    "        state = next_state\n",
    "        frame_idx += 1\n",
    "        \n",
    "            \n",
    "        if frame_idx % save_every_update == 0:\n",
    "            test_rewards.append(np.mean([test_env() for _ in range(10)]))\n",
    "            plot(frame_idx, test_rewards)\n",
    "\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    _, next_value = model(next_state)\n",
    "    returns = compute_gae(next_value, rewards, masks, values)\n",
    "    \n",
    "    log_probs = torch.cat(log_probs).unsqueeze(1).to(device)\n",
    "    returns = torch.cat(returns).detach().to(device)\n",
    "    values = torch.cat(values).to(device)\n",
    "    advantages = returns - values\n",
    "    advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-5)\n",
    "    actions   = torch.cat(actions).unsqueeze(1).to(device)\n",
    "    states = torch.cat(states).to(device)\n",
    "                        \n",
    "    last_al, last_cl, last_el = ppo_update(ppo_epochs, mini_batch_size, states, actions, \n",
    "                log_probs, returns, advantages, values)\n",
    "    \n",
    "            \n",
    "    update_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
