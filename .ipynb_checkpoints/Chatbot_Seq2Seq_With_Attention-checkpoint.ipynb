{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import ast\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seperator = \" +++$+++ \"\n",
    "movie_conversations_path = \"/home/tyler/data/text/cornell_movie_dialogs_corpus/movie_conversations.txt\"\n",
    "movie_lines = \"/home/tyler/data/text/cornell_movie_dialogs_corpus/movie_lines_converted.txt\"\n",
    "MAX_LENGTH = 69 # including EOS tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines_to_words(path):\n",
    "    \"\"\"\n",
    "    path: the path to the file with the words for lines\n",
    "    returns a dictionary mapping from line number to the actually words\n",
    "    \"\"\"\n",
    "    lines_dict = {}\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            columns = line.split(seperator)\n",
    "            lines_dict[columns[0]] = columns[-1]\n",
    "    return lines_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_dict = get_lines_to_words(movie_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_response_pairs(conversations_path, lines_dict):\n",
    "    \"\"\"\n",
    "    conversations_path: the path to the conversation lines\n",
    "    lines_dict: the dictionary mapping from lines to words\n",
    "    returns: list of tuples (context, response)\n",
    "    \n",
    "    Code loops over all lines in a conversation taking the first as the \n",
    "    context and the next as the response. Thus, loop doesn't need to get to\n",
    "    the last line.\n",
    "    \"\"\"\n",
    "    with open(conversations_path, \"r\") as f:\n",
    "        context_response_tuples = []\n",
    "        for line in f:\n",
    "            columns = line.split(seperator)\n",
    "            convs = ast.literal_eval(columns[-1])\n",
    "            for i, spoken_line in enumerate(convs[:-1]):\n",
    "                context = lines_dict[convs[i]]\n",
    "                response = lines_dict[convs[i+1]]\n",
    "                context_response_tuples.append((context, response))\n",
    "        return context_response_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_response_tuples = get_context_response_pairs(movie_conversations_path,\n",
    "                                                    lines_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    #put a space between punctuation, so not included in word\n",
    "    s = s.strip().lower()\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    #remove things that are not letters or punctuation\n",
    "    s = re.sub(r\"[^a-zA-Z.!?']+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def clean_pairs(list_of_pairs, max_length=MAX_LENGTH-1):\n",
    "    \"\"\"\n",
    "    list_of_pairs: list of context, response pairs as raw text\n",
    "    max_length: max length of context or response. 99 percentile is 68\n",
    "    returns list of tuples but each tuple is a list of tokenized words\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    for pair in list_of_pairs:\n",
    "        context = pair[0]\n",
    "        response = pair[1]\n",
    "        context_clean_tokens = normalizeString(context).split(\" \")\n",
    "        response_clean_tokens = normalizeString(response).split(\" \")\n",
    "        if len(context_clean_tokens) > max_length or len(response_clean_tokens) > max_length:\n",
    "            continue\n",
    "        pairs.append((context_clean_tokens, response_clean_tokens))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tuples = clean_pairs(context_response_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Words:\n",
    "    def __init__(self):\n",
    "        self.SOS_token = 0\n",
    "        self.EOS_token = 1\n",
    "        self.word2index = {}\n",
    "        self.index2word = {self.SOS_token: \"SOS\", self.EOS_token: \"EOS\"}\n",
    "        self.word2count = {}\n",
    "        self.n_words = 2\n",
    "        \n",
    "    def __addArray(self, array):\n",
    "        for word in array:\n",
    "            self.__addWord(word)\n",
    "            \n",
    "    def addArrayOfTuples(self, array_of_tuples):\n",
    "        for pair in array_of_tuples:\n",
    "            self.__addArray(pair[0])\n",
    "            self.__addArray(pair[1])\n",
    "    \n",
    "    def __addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = Words()\n",
    "words.addArrayOfTuples(clean_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple encoder network that embeds the character and then feeds through a GRU\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, batch_size, max_length=MAX_LENGTH):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.max_length = max_length\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, self.batch_size, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        result = torch.zeros(1, self.batch_size, self.hidden_size)\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "        \n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Attn Decoder\n",
    "    1. Need max length because learning which input words to attend to\n",
    "    And thus need to know the maximum number of words could attend to\n",
    "    2. The attn_weights tell us how much to weight each input word - in this case French,\n",
    "       In order to predict the english word.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, batch_size,\n",
    "                 dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        # note input and output same size\n",
    "        self.linear = nn.Linear(hidden_size, input_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.attn_layer = nn.Linear(2 * self.hidden_size, MAX_LENGTH)\n",
    "        self.out_layer = nn.Linear(self.hidden_size, input_size)\n",
    "        self.attn_combined_layer = nn.Linear(2 * self.hidden_size, self.hidden_size)\n",
    "    \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, self.batch_size, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        attn = self.attn_layer(torch.cat((embedded[0], hidden[0]),dim=1))\n",
    "        attn_weights = self.softmax(attn)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs) #shape: bx1xh\n",
    "        attn_combined = torch.cat((embedded[0], attn_applied[:,0,:]), 1)\n",
    "        attn_combined = self.relu(self.attn_combined_layer(attn_combined).unsqueeze(0))\n",
    "        output, hidden = self.gru(attn_combined, hidden)\n",
    "        output = self.softmax(self.out_layer(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def initHidden(self):\n",
    "        result = torch.zeros(1, self.batch_size, self.hidden_size)\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 512\n",
    "batch_size = 1\n",
    "encoder = EncoderRNN(words.n_words, hidden_size, batch_size)\n",
    "decoder = AttnDecoderRNN(words.n_words, hidden_size, batch_size)\n",
    "\n",
    "encoder.load_state_dict(torch.load(\"./models/chat_encoder.state\"))\n",
    "decoder.load_state_dict(torch.load(\"./models/chat_decoder.state\"))\n",
    "\n",
    "if use_cuda:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(sentence):\n",
    "    return [words.word2index[word] for word in sentence]\n",
    "\n",
    "def tensorFromSentence(sentence):\n",
    "    indexes = indexesFromSentence(sentence)\n",
    "    indexes.append(words.EOS_token)\n",
    "    # make it 1 column with number of rows equal to words in sentence\n",
    "    result = torch.LongTensor(indexes).view(-1, 1)\n",
    "    pad_amount = MAX_LENGTH - result.size(0)\n",
    "    if pad_amount > 0:\n",
    "        result = F.pad(result, (0,0,0,pad_amount), value=words.EOS_token).data\n",
    "    result = result.cuda() if use_cuda else result\n",
    "    return result\n",
    "    \n",
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    input_variable = tensorFromSentence(normalizeString(sentence).split(\" \"))\n",
    "    input_variable = input_variable.unsqueeze(0)\n",
    "    input_length = input_variable.size()[1]\n",
    "    \n",
    "    encoder_outputs = torch.zeros((batch_size, MAX_LENGTH, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "    \n",
    "    for i in range(input_length):\n",
    "        encoder_ouput, encoder_hidden = encoder.forward(input_variable[:,i,:], encoder_hidden)\n",
    "        encoder_outputs[:,i,:] = encoder_ouput[0]\n",
    "        \n",
    "        \n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoder_input = torch.LongTensor([[words.SOS_token]]*batch_size)\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    decoded_words = []\n",
    "        \n",
    "    for i in range(MAX_LENGTH):\n",
    "        print(decoder_input)\n",
    "        decoder_output, decoder_hidden, attn_weights = decoder.forward(decoder_input, \n",
    "                                                         decoder_hidden,\n",
    "                                                        encoder_outputs)\n",
    "        print(decoder_output.data)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        top_predicted = topi[0][0]\n",
    "        decoder_input = torch.LongTensor([[top_predicted]])\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "        if top_predicted == words.EOS_token:\n",
    "            decoded_words.append(\"<EOS>\")\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[top_predicted])\n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0]], device='cuda:0')\n",
      "tensor([[-31.0352,  -0.0924,  -7.6506,  ..., -29.2614, -17.7012, -22.7200]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<EOS>']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder, decoder, \"can we make\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['can',\n",
       "  'we',\n",
       "  'make',\n",
       "  'this',\n",
       "  'quick',\n",
       "  '?',\n",
       "  'roxanne',\n",
       "  'korrine',\n",
       "  'and',\n",
       "  'andrew',\n",
       "  'barrett',\n",
       "  'are',\n",
       "  'having',\n",
       "  'an',\n",
       "  'incredibly',\n",
       "  'horrendous',\n",
       "  'public',\n",
       "  'break',\n",
       "  'up',\n",
       "  'on',\n",
       "  'the',\n",
       "  'quad',\n",
       "  '.',\n",
       "  'again',\n",
       "  '.'],\n",
       " ['well',\n",
       "  'i',\n",
       "  'thought',\n",
       "  \"we'd\",\n",
       "  'start',\n",
       "  'with',\n",
       "  'pronunciation',\n",
       "  'if',\n",
       "  \"that's\",\n",
       "  'okay',\n",
       "  'with',\n",
       "  'you',\n",
       "  '.'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tuples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
