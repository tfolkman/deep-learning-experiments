{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import ast\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seperator = \" +++$+++ \"\n",
    "movie_conversations_path = \"/home/tyler/data/text/cornell_movie_dialogs_corpus/movie_conversations.txt\"\n",
    "movie_lines = \"/home/tyler/data/text/cornell_movie_dialogs_corpus/movie_lines_converted.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines_to_words(path):\n",
    "    \"\"\"\n",
    "    path: the path to the file with the words for lines\n",
    "    returns a dictionary mapping from line number to the actually words\n",
    "    \"\"\"\n",
    "    lines_dict = {}\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            columns = line.split(seperator)\n",
    "            lines_dict[columns[0]] = columns[-1]\n",
    "    return lines_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_dict = get_lines_to_words(movie_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_response_pairs(conversations_path, lines_dict):\n",
    "    \"\"\"\n",
    "    conversations_path: the path to the conversation lines\n",
    "    lines_dict: the dictionary mapping from lines to words\n",
    "    returns: list of tuples (context, response)\n",
    "    \n",
    "    Code loops over all lines in a conversation taking the first as the \n",
    "    context and the next as the response. Thus, loop doesn't need to get to\n",
    "    the last line.\n",
    "    \"\"\"\n",
    "    with open(conversations_path, \"r\") as f:\n",
    "        context_response_tuples = []\n",
    "        for line in f:\n",
    "            columns = line.split(seperator)\n",
    "            convs = ast.literal_eval(columns[-1])\n",
    "            for i, spoken_line in enumerate(convs[:-1]):\n",
    "                context = lines_dict[convs[i]]\n",
    "                response = lines_dict[convs[i+1]]\n",
    "                context_response_tuples.append((context, response))\n",
    "        return context_response_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_response_tuples = get_context_response_pairs(movie_conversations_path,\n",
    "                                                    lines_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    #put a space between punctuation, so not included in word\n",
    "    s = s.strip().lower()\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    #remove things that are not letters or punctuation\n",
    "    s = re.sub(r\"[^a-zA-Z.!?']+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def clean_pairs(list_of_pairs, max_length=68):\n",
    "    \"\"\"\n",
    "    list_of_pairs: list of context, response pairs as raw text\n",
    "    max_length: max length of context or response. 99 percentile is 68\n",
    "    returns list of tuples but each tuple is a list of tokenized words\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    for pair in list_of_pairs:\n",
    "        context = pair[0]\n",
    "        response = pair[1]\n",
    "        context_clean_tokens = normalizeString(context).split(\" \")\n",
    "        response_clean_tokens = normalizeString(response).split(\" \")\n",
    "        if len(context_clean_tokens) > max_length or len(response_clean_tokens) > max_length:\n",
    "            continue\n",
    "        pairs.append((context_clean_tokens, response_clean_tokens))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tuples = clean_pairs(context_response_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['can',\n",
       "  'we',\n",
       "  'make',\n",
       "  'this',\n",
       "  'quick',\n",
       "  '?',\n",
       "  'roxanne',\n",
       "  'korrine',\n",
       "  'and',\n",
       "  'andrew',\n",
       "  'barrett',\n",
       "  'are',\n",
       "  'having',\n",
       "  'an',\n",
       "  'incredibly',\n",
       "  'horrendous',\n",
       "  'public',\n",
       "  'break',\n",
       "  'up',\n",
       "  'on',\n",
       "  'the',\n",
       "  'quad',\n",
       "  '.',\n",
       "  'again',\n",
       "  '.'],\n",
       " ['well',\n",
       "  'i',\n",
       "  'thought',\n",
       "  \"we'd\",\n",
       "  'start',\n",
       "  'with',\n",
       "  'pronunciation',\n",
       "  'if',\n",
       "  \"that's\",\n",
       "  'okay',\n",
       "  'with',\n",
       "  'you',\n",
       "  '.'])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tuples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\n',\n",
       " \"Well, I thought we'd start with pronunciation, if that's okay with you.\\n\")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_response_tuples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_dict[\"L197\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def readLangs(input_file_location):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open(input_file_location, encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make learning easier, we will limit to sentences less than max length \n",
    "# in either language\n",
    "# And only take sentences that start with certain prefixes\n",
    "# Removed punctuation b/c filtered out in our normalize function\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[0].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "\n",
    "def prepareData(input_file_location):\n",
    "    input_lang, output_lang, pairs = readLangs(input_file_location, lang1_name,\n",
    "                                              lang2_name)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start of sentence\n",
    "SOS_token = 0\n",
    "# end of sentence\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.word2count = {}\n",
    "        self.n_words = 2\n",
    "        \n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.addWord(word)\n",
    "    \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 149861 sentence pairs\n",
      "Trimmed to 11589 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "English 3016\n",
      "French 4634\n",
      "['i m just looking .', 'je ne fais que regarder .']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData(\"../../../data/text/fra-eng/fra.txt\")\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple encoder network that embeds the character and then feeds through a GRU\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, batch_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, self.batch_size, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, self.batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "        \n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Attn Decoder\n",
    "    1. Need max length because learning which input words to attend to\n",
    "    And thus need to know the maximum number of words could attend to\n",
    "    2. The attn_weights tell us how much to weight each input word - in this case French,\n",
    "       In order to predict the english word.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, batch_size,\n",
    "                 dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        # note input and output same size\n",
    "        self.linear = nn.Linear(hidden_size, input_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.attn_layer = nn.Linear(2 * self.hidden_size, MAX_LENGTH)\n",
    "        self.out_layer = nn.Linear(self.hidden_size, input_size)\n",
    "        self.attn_combined_layer = nn.Linear(2 * self.hidden_size, self.hidden_size)\n",
    "    \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, self.batch_size, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        attn = self.attn_layer(torch.cat((embedded[0], hidden[0]),dim=1))\n",
    "        attn_weights = self.softmax(attn)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs) #shape: bx1xh\n",
    "        attn_combined = torch.cat((embedded[0], attn_applied[:,0,:]), 1)\n",
    "        attn_combined = self.relu(self.attn_combined_layer(attn_combined).unsqueeze(0))\n",
    "        output, hidden = self.gru(attn_combined, hidden)\n",
    "        output = self.softmax(self.out_layer(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, self.batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer,\n",
    "         decoder_optimizer, criterion, batch_size, max_length=MAX_LENGTH):\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    loss = 0\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_length = input_variable.size()[1]\n",
    "    target_length = target_variable.size()[1]\n",
    "    \n",
    "    encoder_outputs = Variable(torch.zeros((batch_size, MAX_LENGTH, encoder.hidden_size)))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else decoder_input\n",
    "    \n",
    "    # Here we are feeding in the english words to get the final hidden state \n",
    "    # for the decoder\n",
    "    for i in range(input_length):\n",
    "        encoder_ouput, encoder_hidden = encoder.forward(input_variable[:,i,:], encoder_hidden)\n",
    "        encoder_outputs[:,i,:] = encoder_ouput[0]\n",
    "        \n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]*batch_size))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    # Here we take the final hidden state from the encoder\n",
    "    # And feed it to decoder\n",
    "    # We also give decoder the word to predict the next word starting with SOS token\n",
    "    # If use teacher forcing then give it the truth, otherwise give it prediction\n",
    "    if use_teacher_forcing:\n",
    "        for i in range(target_length):\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder.forward(decoder_input, \n",
    "                                                                           decoder_hidden,\n",
    "                                                                          encoder_outputs)\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[:,i,0])\n",
    "            decoder_input = target_variable[:,i,:]\n",
    "            \n",
    "    else:\n",
    "        for i in range(target_length):\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder.forward(decoder_input, \n",
    "                                                                           decoder_hidden,\n",
    "                                                                           encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[:,i,0])\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            decoder_input = Variable(topi)\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "                \n",
    "    loss.backward()\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, data_loader, epochs, batch_size, print_every=1000,\n",
    "               plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "    \n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    iter = 1\n",
    "    n_iters = len(data_loader) * epochs\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for i_batch, sample_batched in enumerate(data_loader):\n",
    "            \n",
    "            loss = train(Variable(sample_batched[0]), Variable(sample_batched[1]), encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion,\n",
    "                        batch_size)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if iter % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                             iter, iter / n_iters * 100, print_loss_avg))\n",
    "            if iter % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "                \n",
    "            iter = iter + 1\n",
    "            \n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, input_lang, output_lang, max_length):\n",
    "        self.data = data\n",
    "        self.input_lang = input_lang\n",
    "        self.output_lang = output_lang\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data[index]\n",
    "        training_pairs = self.tensorFromPair(row)\n",
    "        return (training_pairs[0], training_pairs[1])\n",
    "    \n",
    "    def indexesFromSentence(self, lang, sentence):\n",
    "        return [lang.word2index[word] for word in sentence.split(\" \")]\n",
    "\n",
    "    def tensorFromSentence(self, lang, sentence):\n",
    "        indexes = self.indexesFromSentence(lang, sentence)\n",
    "        indexes.append(EOS_token)\n",
    "        # make it 1 column with number of rows equal to words in sentence\n",
    "        result = torch.LongTensor(indexes).view(-1, 1)\n",
    "        pad_amount = MAX_LENGTH - result.size(0)\n",
    "        if pad_amount > 0:\n",
    "            result = F.pad(result, (0,0,0,pad_amount), value=EOS_token).data\n",
    "        result = result.cuda() if use_cuda else result\n",
    "        return result\n",
    "\n",
    "    def tensorFromPair(self, pair):\n",
    "        input_variable = self.tensorFromSentence(self.input_lang, pair[0])\n",
    "        output_variable = self.tensorFromSentence(self.output_lang, pair[1])\n",
    "        return (input_variable, output_variable)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "batch_size = 256\n",
    "training_dataset = CustomDataset(pairs, input_lang, output_lang, MAX_LENGTH)\n",
    "training_dataloader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 3s (- 1m 3s) (50 5%) 4.8601\n",
      "0m 7s (- 0m 59s) (100 11%) 3.6264\n",
      "0m 11s (- 0m 55s) (150 16%) 3.2359\n",
      "0m 14s (- 0m 52s) (200 22%) 3.0538\n",
      "0m 18s (- 0m 48s) (250 27%) 2.8982\n",
      "0m 22s (- 0m 44s) (300 33%) 2.8073\n",
      "0m 26s (- 0m 40s) (350 38%) 3.0554\n",
      "0m 29s (- 0m 37s) (400 44%) 2.7399\n",
      "0m 33s (- 0m 33s) (450 50%) 2.6641\n",
      "0m 37s (- 0m 29s) (500 55%) 2.5867\n",
      "0m 40s (- 0m 25s) (550 61%) 2.5530\n",
      "0m 44s (- 0m 22s) (600 66%) 2.4828\n",
      "0m 48s (- 0m 18s) (650 72%) 2.4638\n",
      "0m 51s (- 0m 14s) (700 77%) 2.4226\n",
      "0m 55s (- 0m 11s) (750 83%) 2.3918\n",
      "0m 59s (- 0m 7s) (800 88%) 2.3222\n",
      "1m 3s (- 0m 3s) (850 94%) 2.3179\n",
      "1m 6s (- 0m 0s) (900 100%) 2.3016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0e02398438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0dfb1584a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size, batch_size)\n",
    "decoder = AttnDecoderRNN(output_lang.n_words, hidden_size, batch_size)\n",
    "\n",
    "if use_cuda:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "    \n",
    "trainIters(encoder, decoder, training_dataloader, 20, batch_size, print_every=50,\n",
    "          plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), \"../models/attn_encoder.state\")\n",
    "torch.save(decoder.state_dict(), \"../models/attn_decoder.state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    input_variable = variableFromSentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "\n",
    "    for i in range(input_length):\n",
    "        encoder_ouput, encoder_hidden = encoder.forward(input_variable[i], encoder_hidden)\n",
    "        \n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    decoded_words = []\n",
    "    for i in range(MAX_LENGTH):\n",
    "        decoder_output, decoder_hidden = decoder.forward(decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        top_predicted = topi[0][0]\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[top_predicted]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "        if top_predicted == EOS_token:\n",
    "            decoded_words.append(\"<EOS>\")\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[top_predicted])\n",
    "    return decoded_words\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print(\">\", pair[0])\n",
    "        print(\"=\", pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0])\n",
    "        print(\"<\", \" \".join(output_words))\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(encoder, decoder, \"i m going to teach .\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
