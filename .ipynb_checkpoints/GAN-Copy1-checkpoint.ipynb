{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.datasets as dset\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "num_epochs = 20\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((image_size, image_size)), \n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), \n",
    "                                                     (0.5, 0.5, 0.5)),])\n",
    "dataset = dset.ImageFolder(\"/home/tyler/data/image/celebs/\", \n",
    "                               transform)\n",
    "#dataset = dset.CIFAR10(root = '/home/tyler/data/image', \n",
    "#                       download = True, \n",
    "#                       transform = transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, \n",
    "                                         batch_size = batch_size, \n",
    "                                         shuffle = True, \n",
    "                                         num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## weight initalization for network\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "        \n",
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator\n",
    "\n",
    "Produces an image\n",
    "\n",
    "Q: why the convtranspose2d numbers? A: they are the inverse of discriminator\n",
    "\n",
    "Q: Why first convtranspose2d in channels is 100? This is just a hyper-parameter. You can choose how many channels you want to randomly generate for the input to your generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, d=128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.deconv1 = nn.ConvTranspose2d(100, d*8, 4, 1, 0)\n",
    "        self.deconv1_bn = nn.BatchNorm2d(d*8)\n",
    "        self.deconv2 = nn.ConvTranspose2d(d*8, d*4, 4, 2, 1)\n",
    "        self.deconv2_bn = nn.BatchNorm2d(d*4)\n",
    "        self.deconv3 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)\n",
    "        self.deconv3_bn = nn.BatchNorm2d(d*2)\n",
    "        self.deconv4 = nn.ConvTranspose2d(d*2, d, 4, 2, 1)\n",
    "        self.deconv4_bn = nn.BatchNorm2d(d)\n",
    "        self.deconv5 = nn.ConvTranspose2d(d, 3, 4, 2, 1)\n",
    "\n",
    "    # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "        # x = F.relu(self.deconv1(input))\n",
    "        x = F.relu(self.deconv1_bn(self.deconv1(input)))\n",
    "        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
    "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
    "        x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
    "        x = F.tanh(self.deconv5(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator\n",
    "\n",
    "Just a normal conv net to tell if an image is fake or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, d=128):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, d, 4, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(d*2)\n",
    "        self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(d*4)\n",
    "        self.conv4 = nn.Conv2d(d*4, d*8, 4, 2, 1)\n",
    "        self.conv4_bn = nn.BatchNorm2d(d*8)\n",
    "        self.conv5 = nn.Conv2d(d*8, 1, 4, 1, 0)\n",
    "\n",
    "    # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "        x = F.leaky_relu(self.conv1(input), 0.2)\n",
    "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n",
    "        x = F.sigmoid(self.conv5(x))\n",
    "\n",
    "        return x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator(128).to(device)\n",
    "netG.weight_init(0.0, 0.2)\n",
    "netD = Discriminator(128).to(device)\n",
    "netD.weight_init(0.0, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = 0.00005, betas = (0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = 0.0002, betas = (0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/20], Step [200/1583], d_loss: 5.2368, g_loss: 10.4363, D(x): 0.74, D(G(z)): 0.48\n",
      "Epoch [0/20], Step [400/1583], d_loss: 3.8550, g_loss: 10.0397, D(x): 0.79, D(G(z)): 0.12\n",
      "Epoch [0/20], Step [600/1583], d_loss: 3.3252, g_loss: 10.1054, D(x): 0.84, D(G(z)): 0.22\n",
      "Epoch [0/20], Step [800/1583], d_loss: 7.7377, g_loss: 14.2686, D(x): 0.68, D(G(z)): 0.33\n",
      "Epoch [0/20], Step [1000/1583], d_loss: 8.3376, g_loss: 11.5184, D(x): 0.61, D(G(z)): 0.27\n",
      "Epoch [0/20], Step [1200/1583], d_loss: 6.9064, g_loss: 9.9707, D(x): 0.68, D(G(z)): 0.19\n",
      "Epoch [0/20], Step [1400/1583], d_loss: 5.7491, g_loss: 8.5134, D(x): 0.70, D(G(z)): 0.12\n",
      "Epoch [1/20], Step [200/1583], d_loss: 3.1893, g_loss: 7.5591, D(x): 0.80, D(G(z)): 0.05\n",
      "Epoch [1/20], Step [400/1583], d_loss: 4.2883, g_loss: 8.8692, D(x): 0.79, D(G(z)): 0.10\n",
      "Epoch [1/20], Step [600/1583], d_loss: 2.4908, g_loss: 6.8154, D(x): 0.83, D(G(z)): 0.08\n",
      "Epoch [1/20], Step [800/1583], d_loss: 1.3278, g_loss: 7.1730, D(x): 0.90, D(G(z)): 0.05\n",
      "Epoch [1/20], Step [1000/1583], d_loss: 1.7434, g_loss: 8.1861, D(x): 0.91, D(G(z)): 0.07\n",
      "Epoch [1/20], Step [1200/1583], d_loss: 0.8431, g_loss: 6.6341, D(x): 0.95, D(G(z)): 0.03\n",
      "Epoch [1/20], Step [1400/1583], d_loss: 0.8380, g_loss: 7.5645, D(x): 0.96, D(G(z)): 0.01\n",
      "Epoch [2/20], Step [200/1583], d_loss: 0.1138, g_loss: 6.9134, D(x): 0.99, D(G(z)): 0.02\n",
      "Epoch [2/20], Step [400/1583], d_loss: 0.0117, g_loss: 6.6553, D(x): 1.00, D(G(z)): 0.01\n",
      "Epoch [2/20], Step [600/1583], d_loss: 0.6104, g_loss: 5.9591, D(x): 0.95, D(G(z)): 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-6:\n",
      "Process Process-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9dc0a743d736>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0merrG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_step = len(dataloader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(dataloader):\n",
    "        \n",
    "        ## train discriminator\n",
    "        \n",
    "        netD.zero_grad()\n",
    "        \n",
    "        ## calculate error using real image \n",
    "        real, _ = data\n",
    "        input = Variable(real).to(device)\n",
    "        # target is 1 b/c real image\n",
    "        target = Variable(torch.ones(input.size()[0])).to(device)\n",
    "        output = netD(input)\n",
    "        real_score = output\n",
    "        errD_real = criterion(output, target)\n",
    "        \n",
    "        ## calculate error using fake image\n",
    "        ## first generate an image using generator then discriminate\n",
    "        ## this is 100 channels, 1x1 random noise that the generate will use\n",
    "        noise = Variable(torch.randn(input.size()[0], 100, 1, 1)).to(device)\n",
    "        fake = netG(noise)\n",
    "        target = Variable(torch.zeros(input.size()[0])).to(device)\n",
    "        output = netD(fake.detach())\n",
    "        fake_score = output\n",
    "        errD_fake = criterion(output, target)\n",
    "        \n",
    "        \n",
    "        errD = errD_real + errD_fake\n",
    "        errD.backward()\n",
    "        optimizerD.step()\n",
    "        \n",
    "        \n",
    "        ## train generator\n",
    "        \n",
    "        \n",
    "        ## we want the generator to learn to create realistic images\n",
    "        ## and thus to produce a 1 from the discriminator\n",
    "        netG.zero_grad()\n",
    "        noise = Variable(torch.randn(input.size()[0], 100, 1, 1)).to(device)\n",
    "        fake = netG(noise)\n",
    "        target = Variable(torch.ones(input.size()[0])).to(device)\n",
    "        output = netD(fake)\n",
    "        errG = criterion(output, target)\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        if (i+1) % 200 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
    "                  .format(epoch, num_epochs, i+1, total_step, errD.item(), errG.item(), \n",
    "                    real_score.mean().item(), fake_score.mean().item()))\n",
    "            vutils.save_image(real, '%s/real_samples.png' % \"./results\", normalize = True)\n",
    "            fake = netG(noise)\n",
    "            vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png' % (\"./results\", epoch), normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
