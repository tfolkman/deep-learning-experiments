{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-3:\n",
      "Process Process-8:\n",
      "Process Process-5:\n",
      "Process Process-6:\n",
      "Process Process-2:\n",
      "Process Process-7:\n",
      "Process Process-4:\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from common.multiprocessing_env import SubprocVecEnv\n",
    "\n",
    "num_envs = 8\n",
    "env_name = \"CartPole-v0\"\n",
    "\n",
    "def make_env():\n",
    "    def _thunk():\n",
    "        env = gym.make(env_name)\n",
    "        return env\n",
    "\n",
    "    return _thunk\n",
    "\n",
    "envs = [make_env() for i in range(num_envs)]\n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, hidden_size):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1))\n",
    "        \n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, num_outputs),\n",
    "            nn.Softmax(dim=1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        value = self.critic(x)\n",
    "        probs = self.actor(x)\n",
    "        dist = Categorical(probs)\n",
    "        return dist, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "    \n",
    "def test_env(vis=False):\n",
    "    state = env.reset()\n",
    "    if vis: env.render()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        next_state, reward, done, _ = env.step(dist.sample().cpu().numpy()[0])\n",
    "        state = next_state\n",
    "        if vis: env.render()\n",
    "        total_reward += reward\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gae(next_value, rewards, masks, values, gamma=0.99, tau=0.95):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs  = envs.observation_space.shape[0]\n",
    "num_outputs = envs.action_space.n\n",
    "\n",
    "#Hyper params:\n",
    "max_frames       = 5000\n",
    "hidden_size      = 64\n",
    "lr               = 2.5e-4\n",
    "num_steps        = 128\n",
    "mini_batch_size  = 32\n",
    "ppo_epochs       = 4\n",
    "print_every      = 500\n",
    "\n",
    "model = ActorCritic(num_inputs, num_outputs, hidden_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx    = 0\n",
    "test_rewards = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important\n",
    "\n",
    "With GAE: GAE advantage just used for actor loss. Discounted returns used for critic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## grab random values for each batch\n",
    "def ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantage, values):\n",
    "    batch_size = states.size(0)\n",
    "    sampler = BatchSampler(SubsetRandomSampler(range(batch_size)), \n",
    "                           batch_size // mini_batch_size, \n",
    "                           drop_last=False)\n",
    "    for rand_ids in sampler:\n",
    "        yield states[rand_ids, :], actions[rand_ids, :], log_probs[rand_ids, :], returns[rand_ids, :], advantage[rand_ids, :], values[rand_ids, :]\n",
    "        \n",
    "        \n",
    "def ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, values, clip_param=0.1):\n",
    "    for _ in range(ppo_epochs):\n",
    "        for s, act, lp, r, adv, v in ppo_iter(mini_batch_size, states, actions, log_probs,\n",
    "                                                                       returns, advantages, values):\n",
    "            new_dist, new_value = model(s)\n",
    "            new_entropy = new_dist.entropy().mean()\n",
    "            new_log_prob = new_dist.log_prob(act)\n",
    "            ratio = torch.exp(new_log_prob - lp)\n",
    "            surr1 = ratio * adv\n",
    "            surr2 = torch.clamp(ratio, 1 - clip_param, 1 + clip_param) * adv\n",
    "            actor_loss = - torch.min(surr1, surr2).mean()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            actor_loss = -(lp * adv.detach()).mean()\n",
    "            critic_loss = F.mse_loss(r,v)\n",
    "            loss = (actor_loss + 0.5 * critic_loss - 0.01 * new_entropy).backward(retain_graph=True)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAE/CAYAAABW/Dj8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEyo0EVEwsT/B6NroPy5KdmCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f400428da58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3328603384bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mactions\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mppo_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mppo_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madvantages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-843719076207>\u001b[0m in \u001b[0;36mppo_update\u001b[0;34m(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, values, clip_param)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mcritic_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mactor_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcritic_loss\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.01\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnew_entropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tyler/anaconda3/lib/python3.6/site-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mparam_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mtotal_norm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mparam_norm\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_norm\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "state = envs.reset()\n",
    "\n",
    "while frame_idx < max_frames:\n",
    "    log_probs = []\n",
    "    values = []\n",
    "    rewards = []\n",
    "    masks = []\n",
    "    states = []\n",
    "    actions = []\n",
    "    \n",
    "    for _ in range(num_steps):\n",
    "        # state is 16 x 4 because 16 envs\n",
    "        state = torch.FloatTensor(state).to(device)\n",
    "        states.append(state)\n",
    "        # dist and value each have 16 for all envs\n",
    "        dist, value = model(state)\n",
    "        \n",
    "        # have 16 actions\n",
    "        action = dist.sample()\n",
    "        actions.append(action)\n",
    "        next_state, reward, done, _ = envs.step(action.cpu().numpy())\n",
    "        \n",
    "        log_prob = dist.log_prob(action)\n",
    "\n",
    "        log_probs.append(log_prob)\n",
    "        values.append(value)\n",
    "        # there are 16 rewards. Need to make it 16x1. Same for masks\n",
    "        rewards.append(torch.FloatTensor(reward).unsqueeze(1).to(device))\n",
    "        masks.append(torch.FloatTensor(1 - done).unsqueeze(1).to(device))\n",
    "                \n",
    "        state = next_state\n",
    "        frame_idx += 1\n",
    "        \n",
    "        if frame_idx % print_every == 0:\n",
    "            test_rewards.append(np.mean([test_env() for _ in range(10)]))\n",
    "            plot(frame_idx, test_rewards)\n",
    "            \n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    _, next_value = model(next_state)\n",
    "    returns = compute_gae(next_value, rewards, masks, values)\n",
    "\n",
    "    log_probs = torch.cat(log_probs).unsqueeze(1).to(device)\n",
    "    returns = torch.cat(returns).detach().to(device)\n",
    "    values = torch.cat(values).to(device)\n",
    "    advantages = returns - values\n",
    "    advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-5)\n",
    "    states    = torch.cat(states).to(device)\n",
    "    actions   = torch.cat(actions).unsqueeze(1).to(device)\n",
    "                        \n",
    "    ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
