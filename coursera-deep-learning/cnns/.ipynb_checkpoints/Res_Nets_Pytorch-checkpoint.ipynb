{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Networks\n",
    "\n",
    "Welcome to the second assignment of this week! You will learn how to build very deep convolutional networks, using Residual Networks (ResNets). In theory, very deep networks can represent very complex functions; but in practice, they are hard to train. Residual Networks, introduced by [He et al.](https://arxiv.org/pdf/1512.03385.pdf), allow you to train much deeper networks than were previously practically feasible.\n",
    "\n",
    "**In this assignment, you will:**\n",
    "- Implement the basic building blocks of ResNets. \n",
    "- Put together these building blocks to implement and train a state-of-the-art neural network for image classification. \n",
    "\n",
    "This assignment will be done in Keras. \n",
    "\n",
    "Before jumping into the problem, let's run the cell below to load the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from IPython.display import SVG\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional\n",
    "import math\n",
    "from resnets_utils import load_dataset\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channels, f, in_size, conv_block=False,\n",
    "                s=2):\n",
    "        super(IdentityBlock, self).__init__()\n",
    "        if conv_block:\n",
    "            self.conv1 = nn.Conv2d(in_channel, out_channels[0], 1, s)\n",
    "            out1_size = int(((in_size - 1) / s) + 1)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(in_channel, out_channels[0], 1)\n",
    "            out1_size = int(((in_size - 1) / 1) + 1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels[0])\n",
    "        ## we want same padding here\n",
    "        conv2_padding = int((f-1)/2)\n",
    "        self.conv2 = nn.Conv2d(out_channels[0], out_channels[1], f, \n",
    "                               padding=conv2_padding)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels[1])\n",
    "        self.conv3 = nn.Conv2d(out_channels[1], out_channels[2], 1)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels[2])\n",
    "        \n",
    "        #if conv block need some additional layers\n",
    "        self.conv_block = conv_block\n",
    "        if self.conv_block:\n",
    "            self.shortcut_conv = nn.Conv2d(in_channel, out_channels[2], 1, stride=s)\n",
    "            self.shortcut_bn = nn.BatchNorm2d(out_channels[2])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1_out = functional.relu(self.bn1(self.conv1(x)))\n",
    "        conv2_out = functional.relu(self.bn2(self.conv2(conv1_out)))\n",
    "        conv3_out = self.bn3(self.conv3(conv2_out))\n",
    "        if self.conv_block:\n",
    "            shortcut = self.shortcut_bn(self.shortcut_conv(x))\n",
    "        else:\n",
    "            shortcut = x\n",
    "        return functional.relu(shortcut + conv3_out)\n",
    "    \n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(ResNet50, self).__init__()\n",
    "        \n",
    "        #stage 1\n",
    "        self.conv1 = nn.Conv2d(3, 64, 7, 2, 3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.mp1 = nn.MaxPool2d(3, stride=2)\n",
    "        \n",
    "        #stage 2\n",
    "        self.conv_block1 = IdentityBlock(64, [64,64,256], 3, 15,\n",
    "                                         conv_block=True, s=1)\n",
    "        self.id_block1 = IdentityBlock(256, [64,64,256], 3, 15)\n",
    "        self.id_block2 = IdentityBlock(256, [64,64,256], 3, 15)\n",
    "        \n",
    "        #stage 3\n",
    "        self.conv_block2 = IdentityBlock(256, [128,128,512], 3, 15,\n",
    "                                         conv_block=True, s=2)\n",
    "        self.id_block3 = IdentityBlock(512, [128,128,512], 3, 15)\n",
    "        self.id_block4 = IdentityBlock(512, [128,128,512], 3, 15)\n",
    "        self.id_block5 = IdentityBlock(512, [128,128,512], 3, 15)\n",
    "        \n",
    "        #stage 4\n",
    "        self.conv_block3 = IdentityBlock(512, [256, 256, 1024], 3, 8,\n",
    "                                         conv_block=True, s=2)\n",
    "        self.id_block6 = IdentityBlock(1024, [256, 256, 1024], 3, 8)\n",
    "        self.id_block7 = IdentityBlock(1024, [256, 256, 1024], 3, 8)\n",
    "        self.id_block8 = IdentityBlock(1024, [256, 256, 1024], 3, 8)\n",
    "        self.id_block9 = IdentityBlock(1024, [256, 256, 1024], 3, 8)\n",
    "        self.id_block10 = IdentityBlock(1024, [256, 256, 1024], 3, 8)\n",
    "        \n",
    "        #stage 5\n",
    "        self.conv_block4 = IdentityBlock(1024, [512, 512, 2048], 3, 4,\n",
    "                                         conv_block=True, s=2)\n",
    "        self.id_block11 = IdentityBlock(2048, [512, 512, 2048], 3, 4)\n",
    "        self.id_block12 = IdentityBlock(2048, [512, 512, 2048], 3, 4)\n",
    "        \n",
    "        #stage 6\n",
    "        self.ap = nn.AvgPool2d(2)\n",
    "        self.linear = nn.Linear(2048, classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.mp1(functional.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.id_block2(self.id_block1(x))\n",
    "        x = self.id_block5(self.id_block4(self.id_block3(self.conv_block2(x))))\n",
    "        x = self.id_block8(self.id_block7(self.id_block6(self.conv_block3(x))))\n",
    "        x = self.id_block10(self.id_block9(x))\n",
    "        x = self.id_block12(self.id_block11(self.conv_block4(x)))\n",
    "        x = self.ap(x).view(batch_size, -1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 64, 64, 3)\n",
      "Y_train shape: (1, 1080)\n",
      "X_test shape: (120, 64, 64, 3)\n",
      "Y_test shape: (1, 120)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train, X_test_orig, Y_test, classes = load_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "resnet = ResNet50(6).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1661,  0.3251,  0.0765,  0.3080, -0.1592,  0.1753]], device='cuda:0')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_in = torch.FloatTensor(X_train[0]).view(1,3,64,64).to(device)\n",
    "\n",
    "resnet(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs = 2, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            ** Epoch 1/2**\n",
    "        </td>\n",
    "        <td>\n",
    "           loss: between 1 and 5, acc: between 0.2 and 0.5, although your results can be different from ours.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            ** Epoch 2/2**\n",
    "        </td>\n",
    "        <td>\n",
    "           loss: between 1 and 5, acc: between 0.2 and 0.5, you should see your loss decreasing and the accuracy increasing.\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this model (trained on only two epochs) performs on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **Test Accuracy**\n",
    "        </td>\n",
    "        <td>\n",
    "           between 0.16 and 0.25\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this assignment, we've asked you to train the model only for two epochs. You can see that it achieves poor performances. Please go ahead and submit your assignment; to check correctness, the online grader will run your code only for a small number of epochs as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have finished this official (graded) part of this assignment, you can also optionally train the ResNet for more iterations, if you want. We get a lot better performance when we train for ~20 epochs, but this will take more than an hour when training on a CPU. \n",
    "\n",
    "Using a GPU, we've trained our own ResNet50 model's weights on the SIGNS dataset. You can load and run our trained model on the test set in the cells below. It may take â‰ˆ1min to load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('ResNet50.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50 is a powerful model for image classification when it is trained for an adequate number of iterations. We hope you can use what you've learnt and apply it to your own classification problem to perform state-of-the-art accuracy.\n",
    "\n",
    "Congratulations on finishing this assignment! You've now implemented a state-of-the-art image classification system! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Test on your own image (Optional/Ungraded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish, you can also take a picture of your own hand and see the output of the model. To do this:\n",
    "    1. Click on \"File\" in the upper bar of this notebook, then click \"Open\" to go on your Coursera Hub.\n",
    "    2. Add your image to this Jupyter Notebook's directory, in the \"images\" folder\n",
    "    3. Write your image's name in the following code\n",
    "    4. Run the code and check if the algorithm is right! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'images/my_image.jpg'\n",
    "img = image.load_img(img_path, target_size=(64, 64))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "print('Input image shape:', x.shape)\n",
    "my_image = scipy.misc.imread(img_path)\n",
    "imshow(my_image)\n",
    "print(\"class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] = \")\n",
    "print(model.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also print a summary of your model by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the code below to visualize your ResNet50. You can also download a .png picture of your model by going to \"File -> Open...-> model.png\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model.png')\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "**What you should remember:**\n",
    "- Very deep \"plain\" networks don't work in practice because they are hard to train due to vanishing gradients.  \n",
    "- The skip-connections help to address the Vanishing Gradient problem. They also make it easy for a ResNet block to learn an identity function. \n",
    "- There are two main type of blocks: The identity block and the convolutional block. \n",
    "- Very deep Residual Networks are built by stacking these blocks together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References \n",
    "\n",
    "This notebook presents the ResNet algorithm due to He et al. (2015). The implementation here also took significant inspiration and follows the structure given in the github repository of Francois Chollet: \n",
    "\n",
    "- Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun - [Deep Residual Learning for Image Recognition (2015)](https://arxiv.org/abs/1512.03385)\n",
    "- Francois Chollet's github repository: https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py\n"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "OEpi5",
   "launcher_item_id": "jK9EQ"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
