{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as fn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as data\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import operator\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_name = {0: \"Heart\", 1: \"Baseball\", 2: \"Smile\", 3: \"Disappointed\",\n",
    "                4: \"Fork and Knife\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            columns = line.split(\",\")\n",
    "            sentences.append(columns[0].replace('\"',\"\").lower().strip())\n",
    "            labels.append(int(columns[1]))\n",
    "    return sentences, labels\n",
    "\n",
    "def read_glove_vecs(path):\n",
    "    word_to_vec_map = {}\n",
    "    word_to_index = {}\n",
    "    index_to_word = {}\n",
    "    with open(path, \"r\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            columns = line.split(\" \")\n",
    "            word = columns[0]\n",
    "            vector = columns[1:]\n",
    "            word_to_vec_map[word] = [float(v.strip()) for v in vector]\n",
    "            word_to_index[word] = i\n",
    "            index_to_word[i] = word\n",
    "    return word_to_index, index_to_word, word_to_vec_map\n",
    "\n",
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    avg = np.zeros((50,))\n",
    "    words = [i.lower() for i in sentence.split()]\n",
    "    for word in words:\n",
    "        avg += word_to_vec_map[word]\n",
    "    avg = avg / len(words)\n",
    "    return avg\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.linear = nn.Linear(50, 25)\n",
    "        self.linear2 = nn.Linear(25, 5)\n",
    "        \n",
    "    def forward(self, avg):\n",
    "        return fn.softmax(self.linear2(self.linear(avg)), dim=0)\n",
    "    \n",
    "def predict(sentence, classifier):\n",
    "    avg = sentence_to_avg(sentence, word_to_vec_map)\n",
    "    avg = torch.FloatTensor(avg).to(device)\n",
    "    predictions = classifier(avg)\n",
    "    prediction = predictions.argmax().item()\n",
    "    return class_to_name[prediction], prediction\n",
    "\n",
    "def evaluate(sentences, labels, classifier):\n",
    "    correct = 0\n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        label = labels[i]\n",
    "        class_name, class_index = predict(sentence, classifier)\n",
    "        correct += class_index == label\n",
    "    return correct / len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avg Embeddings Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_sentences, train_labels = read_data(\"/home/tyler/data/text/emoji/train_emoji.csv\")\n",
    "test_sentences, test_labels = read_data(\"/home/tyler/data/text/emoji/tesss.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = len(max(train_sentences, key=len).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('/home/tyler/data/text/glove/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier().to(device)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for epoch in range(n_epochs):\n",
    "    sentences, labels = shuffle(train_sentences, train_labels)\n",
    "    loss_avg = 0\n",
    "    for i in range(len(sentences)):\n",
    "        \n",
    "        classifier.zero_grad()\n",
    "        \n",
    "        sentence = sentences[i]\n",
    "        label = torch.LongTensor([labels[i]]).to(device)\n",
    "        \n",
    "        avg = sentence_to_avg(sentence, word_to_vec_map)\n",
    "        avg = torch.FloatTensor(avg).to(device)\n",
    "        predictions = classifier(avg)\n",
    "        loss = criterion(predictions.unsqueeze(0), label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_avg += loss.item()\n",
    "    losses.append(loss_avg / len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"lets play ball\", classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(test_sentences, test_labels, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(train_sentences, train_labels, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert embedding dict to numpy matrix\n",
    "glove_numpy = np.zeros((len(word_to_vec_map)+1, 50))\n",
    "for i in range(len(index_to_word)):\n",
    "    glove_numpy[i,:] = word_to_vec_map[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmojiDataset(data.Dataset):\n",
    "    def __init__(self, sentences, labels, word_to_index, max_len):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.word_to_index = word_to_index\n",
    "        self.len = len(labels)\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def sentence_to_indexes(self, sentence):\n",
    "        indexes = np.full(max_len, 400000)\n",
    "        for i, word in enumerate(sentence.split()):\n",
    "            indexes[i] = word_to_index[word]\n",
    "        return indexes\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        sentence = self.sentences[index]\n",
    "        label = self.labels[index]\n",
    "        sentence_tensor = torch.LongTensor(self.sentence_to_indexes(sentence))\n",
    "        return sentence_tensor, torch.LongTensor([label]), torch.LongTensor([len(sentence.split())])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "emoji = EmojiDataset(train_sentences, train_labels, word_to_index, max_len)\n",
    "data_loader = data.DataLoader(dataset=emoji,\n",
    "                             batch_size=8,\n",
    "                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(400001, 50, padding_idx=400000)\n",
    "        self.embedding.weight.data.copy_(torch.from_numpy(glove_numpy))\n",
    "        # Don't train the embedding layer since don't have much data\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.lstm = nn.LSTM(50, 128, 2, dropout=0.50,\n",
    "                            batch_first=True)\n",
    "        self.linear = nn.Linear(128, 5)\n",
    "        \n",
    "    def forward(self, sentence_indexes, lengths):\n",
    "        embeds = self.embedding(sentence_indexes)\n",
    "        # the packed sequence allows us to use -1 to get the last non-padded word\n",
    "        packed = pack_padded_sequence(embeds, list(lengths.data), batch_first=True)\n",
    "        rnn, _ = self.lstm(embeds)\n",
    "        # only take last value from LSTM\n",
    "        out = self.linear(rnn[:,-1,:])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "lstm = LSTMClassifier()\n",
    "lstm.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, lstm.parameters()), \n",
    "                       lr=0.001)\n",
    "losses = []\n",
    "for epoch in range(n_epochs):\n",
    "    loss_avg = 0\n",
    "    for i, (sentence_indexes, label, length) in enumerate(data_loader):\n",
    "        \n",
    "        si2 = np.zeros((sentence_indexes.shape[0], sentence_indexes.shape[1]))\n",
    "        \n",
    "        # need to sort them for padding\n",
    "        sentence_indexes, length, label = zip(*sorted(zip(\n",
    "            sentence_indexes.numpy(), \n",
    "            length.numpy(), label.numpy()), \n",
    "            key=operator.itemgetter(1), reverse=True))\n",
    "        \n",
    "        length = torch.LongTensor(np.array([x[0] for x in length])).unsqueeze(-1)\n",
    "        label = torch.LongTensor(np.array([x[0] for x in label])).unsqueeze(-1)\n",
    "        \n",
    "        for i, s in enumerate(sentence_indexes):\n",
    "            si2[i,:] = s\n",
    "        \n",
    "        sentence_indexes = torch.LongTensor(si2)\n",
    "        \n",
    "        sentence_indexes = sentence_indexes.to(device)\n",
    "        label = label.to(device)\n",
    "        length = length.to(device)\n",
    "        lstm.zero_grad()\n",
    "        predictions = lstm(sentence_indexes, length)\n",
    "        loss = criterion(predictions, label.squeeze(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_avg += loss.item()\n",
    "    if epoch % 25 == 0:\n",
    "        print(epoch)\n",
    "    losses.append(loss_avg / len(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4c099b9198>]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4c09e34128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence, classifier):\n",
    "        classifier.eval()\n",
    "        indexes = np.full(max_len, 400000)\n",
    "        for i, word in enumerate([l.lower() for l in sentence.split()]):\n",
    "            indexes[i] = word_to_index[word]\n",
    "        indexes = torch.LongTensor(indexes).to(device)\n",
    "        indexes = indexes.unsqueeze(0)\n",
    "        predictions = classifier(indexes, torch.LongTensor([len(sentence.split())]))\n",
    "        prediction = predictions.argmax().item()\n",
    "        return class_to_name[prediction], prediction\n",
    "    \n",
    "def evaluate(sentences, labels, classifier):\n",
    "    correct = 0\n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        label = labels[i]\n",
    "        class_name, class_index = predict(sentence, classifier)\n",
    "        correct += class_index == label\n",
    "    return correct / len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Disappointed', 3)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"im not happy to see you\", lstm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
