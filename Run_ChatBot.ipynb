{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import ast\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Words:\n",
    "    def __init__(self):\n",
    "        self.SOS_token = 0\n",
    "        self.EOS_token = 1\n",
    "        self.word2index = {}\n",
    "        self.index2word = {self.SOS_token: \"SOS\", self.EOS_token: \"EOS\"}\n",
    "        self.word2count = {}\n",
    "        self.n_words = 2\n",
    "        \n",
    "    def __addArray(self, array):\n",
    "        for word in array:\n",
    "            self.__addWord(word)\n",
    "            \n",
    "    def addArrayOfTuples(self, array_of_tuples):\n",
    "        for pair in array_of_tuples:\n",
    "            self.__addArray(pair[0])\n",
    "            self.__addArray(pair[1])\n",
    "    \n",
    "    def __addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = Words()\n",
    "words.addArrayOfTuples(clean_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple encoder network that embeds the character and then feeds through a GRU\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, batch_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, self.batch_size, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        result = torch.zeros(1, self.batch_size, self.hidden_size)\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "        \n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Attn Decoder\n",
    "    1. Need max length because learning which input words to attend to\n",
    "    And thus need to know the maximum number of words could attend to\n",
    "    2. The attn_weights tell us how much to weight each input word - in this case French,\n",
    "       In order to predict the english word.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, batch_size,\n",
    "                 dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        # note input and output same size\n",
    "        self.linear = nn.Linear(hidden_size, input_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.attn_layer = nn.Linear(2 * self.hidden_size, MAX_LENGTH)\n",
    "        self.out_layer = nn.Linear(self.hidden_size, input_size)\n",
    "        self.attn_combined_layer = nn.Linear(2 * self.hidden_size, self.hidden_size)\n",
    "    \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, self.batch_size, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        attn = self.attn_layer(torch.cat((embedded[0], hidden[0]),dim=1))\n",
    "        attn_weights = self.softmax(attn)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs) #shape: bx1xh\n",
    "        attn_combined = torch.cat((embedded[0], attn_applied[:,0,:]), 1)\n",
    "        attn_combined = self.relu(self.attn_combined_layer(attn_combined).unsqueeze(0))\n",
    "        output, hidden = self.gru(attn_combined, hidden)\n",
    "        output = self.softmax(self.out_layer(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def initHidden(self):\n",
    "        result = torch.zeros(1, self.batch_size, self.hidden_size)\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer,\n",
    "         decoder_optimizer, criterion, batch_size, SOS_token=words.SOS_token, max_length=MAX_LENGTH):\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    loss = 0\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_length = input_variable.size()[1]\n",
    "    target_length = target_variable.size()[1]\n",
    "    \n",
    "    encoder_outputs = torch.zeros((batch_size, MAX_LENGTH, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else decoder_input\n",
    "    \n",
    "    # Here we are feeding in the english words to get the final hidden state \n",
    "    # for the decoder\n",
    "    for i in range(input_length):\n",
    "        encoder_ouput, encoder_hidden = encoder.forward(input_variable[:,i,:], encoder_hidden)\n",
    "        encoder_outputs[:,i,:] = encoder_ouput[0]\n",
    "        \n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoder_input = torch.LongTensor([[SOS_token]]*batch_size)\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    # Here we take the final hidden state from the encoder\n",
    "    # And feed it to decoder\n",
    "    # We also give decoder the word to predict the next word starting with SOS token\n",
    "    # If use teacher forcing then give it the truth, otherwise give it prediction\n",
    "    if use_teacher_forcing:\n",
    "        for i in range(target_length):\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder.forward(decoder_input, \n",
    "                                                                           decoder_hidden,\n",
    "                                                                          encoder_outputs)\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[:,i,0])\n",
    "            decoder_input = target_variable[:,i,:]\n",
    "            \n",
    "    else:\n",
    "        for i in range(target_length):\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder.forward(decoder_input, \n",
    "                                                                           decoder_hidden,\n",
    "                                                                           encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[:,i,0])\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            decoder_input = topi\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "                \n",
    "    loss.backward()\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, data_loader, epochs, batch_size, print_every=1000,\n",
    "               plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "    \n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    iter = 1\n",
    "    n_iters = len(data_loader) * epochs\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for i_batch, sample_batched in enumerate(data_loader):\n",
    "            \n",
    "            \n",
    "            loss = train(sample_batched[0], sample_batched[1], encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion,\n",
    "                        batch_size)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if iter % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                             iter, iter / n_iters * 100, print_loss_avg))\n",
    "            if iter % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "                \n",
    "            iter = iter + 1\n",
    "            \n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, words, max_length):\n",
    "        self.data = data\n",
    "        self.words = words\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data[index]\n",
    "        training_pairs = self.tensorFromPair(row)\n",
    "        return (training_pairs[0], training_pairs[1])\n",
    "    \n",
    "    def indexesFromSentence(self, sentence):\n",
    "        return [self.words.word2index[word] for word in sentence]\n",
    "\n",
    "    def tensorFromSentence(self, sentence):\n",
    "        indexes = self.indexesFromSentence(sentence)\n",
    "        indexes.append(self.words.EOS_token)\n",
    "        # make it 1 column with number of rows equal to words in sentence\n",
    "        result = torch.LongTensor(indexes).view(-1, 1)\n",
    "        pad_amount = self.max_length - result.size(0)\n",
    "        if pad_amount > 0:\n",
    "            result = F.pad(result, (0,0,0,pad_amount), value=self.words.EOS_token).data\n",
    "        result = result.cuda() if use_cuda else result\n",
    "        return result\n",
    "\n",
    "    def tensorFromPair(self, pair):\n",
    "        input_variable = self.tensorFromSentence(pair[0])\n",
    "        output_variable = self.tensorFromSentence(pair[1])\n",
    "        return (input_variable, output_variable)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "batch_size = 256\n",
    "training_dataset = CustomDataset(clean_tuples, words, MAX_LENGTH) # add 1 for EOS\n",
    "training_dataloader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:59: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 30s (- 170m 13s) (50 0%) 13.8939\n",
      "1m 0s (- 169m 27s) (100 0%) 15.5410\n",
      "1m 29s (- 168m 10s) (150 0%) 13.3282\n",
      "1m 59s (- 167m 59s) (200 1%) 12.5567\n",
      "2m 29s (- 167m 38s) (250 1%) 13.8714\n",
      "2m 59s (- 167m 3s) (300 1%) 13.2945\n",
      "3m 29s (- 166m 28s) (350 2%) 13.5684\n",
      "3m 59s (- 165m 54s) (400 2%) 13.2567\n",
      "4m 29s (- 165m 26s) (450 2%) 13.4829\n",
      "4m 59s (- 164m 58s) (500 2%) 12.1789\n",
      "5m 28s (- 164m 21s) (550 3%) 12.4293\n",
      "5m 58s (- 163m 50s) (600 3%) 13.0382\n",
      "6m 29s (- 163m 30s) (650 3%) 11.9227\n",
      "6m 59s (- 163m 0s) (700 4%) 12.3920\n",
      "7m 29s (- 162m 38s) (750 4%) 12.1851\n",
      "7m 58s (- 162m 2s) (800 4%) 12.1708\n",
      "8m 28s (- 161m 32s) (850 4%) 11.2850\n",
      "8m 58s (- 161m 4s) (900 5%) 10.7802\n",
      "9m 28s (- 160m 33s) (950 5%) 11.7264\n",
      "9m 58s (- 159m 59s) (1000 5%) 11.6277\n",
      "10m 28s (- 159m 25s) (1050 6%) 11.6710\n",
      "10m 58s (- 158m 57s) (1100 6%) 12.7896\n",
      "11m 28s (- 158m 28s) (1150 6%) 11.8657\n",
      "11m 57s (- 157m 57s) (1200 7%) 12.1697\n",
      "12m 27s (- 157m 27s) (1250 7%) 11.3007\n",
      "12m 57s (- 156m 55s) (1300 7%) 12.2772\n",
      "13m 27s (- 156m 29s) (1350 7%) 12.4880\n",
      "13m 58s (- 156m 2s) (1400 8%) 11.6144\n",
      "14m 27s (- 155m 28s) (1450 8%) 12.4983\n",
      "14m 57s (- 155m 1s) (1500 8%) 11.1107\n",
      "15m 27s (- 154m 27s) (1550 9%) 12.8240\n",
      "15m 57s (- 154m 2s) (1600 9%) 12.5346\n",
      "16m 27s (- 153m 34s) (1650 9%) 12.1998\n",
      "16m 57s (- 153m 2s) (1700 9%) 12.1330\n",
      "17m 27s (- 152m 34s) (1750 10%) 12.7754\n",
      "17m 58s (- 152m 7s) (1800 10%) 11.8300\n",
      "18m 28s (- 151m 38s) (1850 10%) 12.5125\n",
      "18m 57s (- 151m 7s) (1900 11%) 11.5914\n",
      "19m 27s (- 150m 38s) (1950 11%) 12.1613\n",
      "19m 58s (- 150m 9s) (2000 11%) 11.7210\n",
      "20m 28s (- 149m 40s) (2050 12%) 13.0405\n",
      "20m 58s (- 149m 10s) (2100 12%) 12.2528\n",
      "21m 27s (- 148m 37s) (2150 12%) 12.0300\n",
      "21m 57s (- 148m 8s) (2200 12%) 11.2667\n",
      "22m 27s (- 147m 38s) (2250 13%) 10.8041\n",
      "22m 57s (- 147m 9s) (2300 13%) 11.5281\n",
      "23m 27s (- 146m 39s) (2350 13%) 11.1081\n",
      "23m 57s (- 146m 7s) (2400 14%) 9.7846\n",
      "24m 26s (- 145m 35s) (2450 14%) 10.6066\n",
      "24m 57s (- 145m 7s) (2500 14%) 10.3544\n",
      "25m 27s (- 144m 39s) (2550 14%) 9.9733\n",
      "25m 57s (- 144m 12s) (2600 15%) 11.2026\n",
      "26m 27s (- 143m 41s) (2650 15%) 10.7326\n",
      "26m 57s (- 143m 13s) (2700 15%) 10.2426\n",
      "27m 27s (- 142m 43s) (2750 16%) 10.4318\n",
      "27m 57s (- 142m 10s) (2800 16%) 10.5361\n",
      "28m 27s (- 141m 41s) (2850 16%) 10.7062\n",
      "28m 57s (- 141m 12s) (2900 17%) 10.8128\n",
      "29m 27s (- 140m 42s) (2950 17%) 10.4233\n",
      "29m 57s (- 140m 11s) (3000 17%) 10.8552\n",
      "30m 27s (- 139m 40s) (3050 17%) 10.3242\n",
      "30m 56s (- 139m 8s) (3100 18%) 10.0896\n",
      "31m 27s (- 138m 40s) (3150 18%) 10.1788\n",
      "31m 56s (- 138m 10s) (3200 18%) 9.8568\n",
      "32m 26s (- 137m 40s) (3250 19%) 11.0563\n",
      "32m 57s (- 137m 12s) (3300 19%) 10.4050\n",
      "33m 26s (- 136m 41s) (3350 19%) 10.3801\n",
      "33m 57s (- 136m 12s) (3400 19%) 10.3684\n",
      "34m 27s (- 135m 44s) (3450 20%) 10.2888\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder = EncoderRNN(words.n_words, hidden_size, batch_size)\n",
    "decoder = AttnDecoderRNN(words.n_words, hidden_size, batch_size)\n",
    "\n",
    "if use_cuda:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "    \n",
    "trainIters(encoder, decoder, training_dataloader, 20, batch_size, print_every=50,\n",
    "          plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), \"../models/attn_encoder.state\")\n",
    "torch.save(decoder.state_dict(), \"../models/attn_decoder.state\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    input_variable = variableFromSentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "\n",
    "    for i in range(input_length):\n",
    "        encoder_ouput, encoder_hidden = encoder.forward(input_variable[i], encoder_hidden)\n",
    "        \n",
    "    decoder_hidden = encoder_hidden\n",
    "    decoder_input = torch.LongTensor([[SOS_token]])\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    decoded_words = []\n",
    "    for i in range(MAX_LENGTH):\n",
    "        decoder_output, decoder_hidden = decoder.forward(decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        top_predicted = topi[0][0]\n",
    "\n",
    "        decoder_input = torch.LongTensor([[top_predicted]])\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "        if top_predicted == EOS_token:\n",
    "            decoded_words.append(\"<EOS>\")\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[top_predicted])\n",
    "    return decoded_words\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print(\">\", pair[0])\n",
    "        print(\"=\", pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0])\n",
    "        print(\"<\", \" \".join(output_words))\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(encoder, decoder, \"i m going to teach .\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
