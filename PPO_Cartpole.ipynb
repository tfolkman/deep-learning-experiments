{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/tyler/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "from gym.spaces.box import Box\n",
    "\n",
    "from baselines import bench\n",
    "from baselines.common.atari_wrappers import make_atari, wrap_deepmind\n",
    "from baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_envs = 8\n",
    "lr               = 2.5e-4\n",
    "num_steps        = 30\n",
    "mini_batch_size  = 5\n",
    "ppo_epochs       = 4\n",
    "save_every_update = 50\n",
    "gamma = 0.99\n",
    "tau = 0.95\n",
    "critic_weight = 1.0\n",
    "entropy_weight = 0.01\n",
    "clip_param = 0.1\n",
    "max_frames  = 5000\n",
    "\n",
    "\n",
    "render = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(env_id, seed, rank):\n",
    "    def _thunk():\n",
    "        if env_id.startswith(\"dm\"):\n",
    "            _, domain, task = env_id.split('.')\n",
    "            env = dm_control2gym.make(domain_name=domain, task_name=task)\n",
    "        else:\n",
    "            env = gym.make(env_id)\n",
    "        is_atari = hasattr(gym.envs, 'atari') and isinstance(\n",
    "            env.unwrapped, gym.envs.atari.atari_env.AtariEnv)\n",
    "        if is_atari:\n",
    "            # Does some pre-processing that affects pong\n",
    "            # 1) Samples initial states by taking random number of no-ops\n",
    "            #    on reset (at most 30)\n",
    "            # 2) Returns only every 4th frame\n",
    "            env = make_atari(env_id)\n",
    "        env.seed(seed + rank)\n",
    "\n",
    "\n",
    "        if is_atari:\n",
    "            # Does some pre-processing that affects pong\n",
    "            # 1) Make end-of-life == end-of-episode, but only reset on true game over\n",
    "            # 2) Warp frames to 84x84\n",
    "            # 3) Stack 4 frames\n",
    "            # 4) Scale the image by dividing by 255\n",
    "            env = wrap_deepmind(env, frame_stack=True, scale=True)\n",
    "\n",
    "        return env\n",
    "\n",
    "    return _thunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-5:\n",
      "Process Process-3:\n",
      "Process Process-7:\n",
      "Process Process-2:\n",
      "Process Process-1:\n",
      "Process Process-4:\n",
      "Process Process-8:\n",
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from common.multiprocessing_env import SubprocVecEnv\n",
    "\n",
    "env_name = \"CartPole-v0\"\n",
    "seed = 42\n",
    "\n",
    "\n",
    "envs = [make_env(env_name, seed, i)\n",
    "        for i in range(num_envs)]\n",
    "\n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_normc_(weight, gain=1):\n",
    "    weight.normal_(0, 1)\n",
    "    weight *= gain / torch.sqrt(weight.pow(2).sum(1, keepdim=True))\n",
    "    \n",
    "def init(module, weight_init, bias_init, gain=1):\n",
    "    weight_init(module.weight.data, gain=gain)\n",
    "    bias_init(module.bias.data)\n",
    "    return module\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        init_ = lambda m: init(m,\n",
    "              init_normc_,\n",
    "              lambda x: nn.init.constant_(x, 0))\n",
    "\n",
    "        self.actor = nn.Sequential(\n",
    "            init_(nn.Linear(num_inputs, 64)),\n",
    "            nn.Tanh(),\n",
    "            init_(nn.Linear(64, 64)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.critic = nn.Sequential(\n",
    "            init_(nn.Linear(num_inputs, 64)),\n",
    "            nn.Tanh(),\n",
    "            init_(nn.Linear(64, 64)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.critic_linear = init_(nn.Linear(64, 1))\n",
    "        self.actor_linear   = init_(nn.Linear(64, num_outputs))\n",
    "                         \n",
    "    def forward(self, x):\n",
    "        value = self.critic_linear(self.critic(x))\n",
    "        softs = F.softmax(self.actor_linear(self.actor(x)), dim=1)\n",
    "        dist = Categorical(softs)\n",
    "        return dist, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "    \n",
    "def test_env(vis=False):\n",
    "    state = env.reset()\n",
    "    if vis: env.render()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        next_state, reward, done, _ = env.step(dist.sample().cpu().numpy()[0])\n",
    "        state = next_state\n",
    "        if vis: env.render()\n",
    "        total_reward += reward\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gae(next_value, rewards, masks, values, gamma=gamma, tau=tau):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outputs = envs.action_space.n\n",
    "\n",
    "model = ActorCritic(4, num_outputs).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, eps=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx    = 0\n",
    "test_rewards = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important\n",
    "\n",
    "With GAE: GAE advantage just used for actor loss. Discounted returns used for critic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## grab random values for each batch\n",
    "def ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantage, values):\n",
    "    batch_size = states.size(0)\n",
    "    sampler = BatchSampler(SubsetRandomSampler(range(batch_size)), \n",
    "                           mini_batch_size, \n",
    "                           drop_last=False)\n",
    "    for rand_ids in sampler:\n",
    "        yield states[rand_ids, :], actions[rand_ids, :], log_probs[rand_ids, :], returns[rand_ids, :], advantage[rand_ids, :], values[rand_ids, :]\n",
    "        \n",
    "        \n",
    "def ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, values, clip_param=clip_param):\n",
    "    for _ in range(ppo_epochs):\n",
    "        for s, act, lp, r, adv, v in ppo_iter(mini_batch_size, states, actions, log_probs,\n",
    "                                                                       returns, advantages, values):\n",
    "            \n",
    "            act = act.squeeze(1)\n",
    "            lp = lp.squeeze(1)\n",
    "            adv = adv.squeeze(1).detach()\n",
    "                        \n",
    "            new_dist, new_value = model(s)\n",
    "            new_entropy = new_dist.entropy().mean()\n",
    "            new_log_prob = new_dist.log_prob(act)\n",
    "            ratio = torch.exp(new_log_prob - lp)            \n",
    "            surr1 = ratio * adv\n",
    "            clamped_ratio = torch.clamp(ratio, 1.0 - clip_param, 1.0 + clip_param)\n",
    "            surr2 =  clamped_ratio * adv\n",
    "            \n",
    "            actor_loss_1 = -torch.min(surr1, surr2).mean()\n",
    "            actor_loss = -(lp * adv).mean()\n",
    "            \n",
    "            critic_loss = F.mse_loss(r,new_value)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = (actor_loss + critic_weight * critic_loss - entropy_weight * new_entropy)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "    return actor_loss, critic_loss, -new_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAE/CAYAAACNR5LeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.5207, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1630, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.3371, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.5448, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.7247, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.8036, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.2863, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0961, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.7500, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.4798, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.9340, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2351, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.2836, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0665, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.9357, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.2265, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.2472, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.0321, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.5713, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.4363, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.8227, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.5940, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.2444, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0955, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.5779, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.9482, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.2011, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1362, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.0535, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1542, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.4424, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2123, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.0797, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3299, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.4876, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.6381, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.1189, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.2559, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.4410, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.0613, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.3870, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2595, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.3272, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2286, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.5525, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.5452, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.5092, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1322, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.8058, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.3253, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.0579, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.0168, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.2778, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.2492, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.3706, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3249, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.4631, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2308, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.3954, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.0730, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.1627, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1240, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.4371, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2790, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.1593, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.9559, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.0489, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0434, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.5491, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1907, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.5154, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.2729, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.1270, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1110, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.6536, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.1067, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.4147, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.2924, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.1548, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.0509, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-1.0466, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.7630, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.2988, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1969, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.5945, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.5061, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.4891, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0445, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.1801, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.1016, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.5805, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.3573, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.4266, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0308, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.6110, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.0487, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.0309, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1066, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.6441, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3962, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.5202, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.1665, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.3801, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.1458, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.2022, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.3337, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1179, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.5257, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2202, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.2162, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0851, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.5155, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1743, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.4537, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1983, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.5044, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.3560, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.1029, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2224, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.0892, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1504, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.4386, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.1144, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(1.0105, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.6857, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.7305, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1451, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.3964, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3739, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.2872, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2296, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.0086, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.2096, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.2761, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.6448, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1936, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.9892, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.2700, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.1356, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.2951, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-1.0882, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.8030, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.2923, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4862, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.3896, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.1718, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.2464, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.7325, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2650, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.6197, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3246, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.3005, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0188, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.8145, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.2304, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.2781, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0783, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.4482, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.1025, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.3758, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.3078, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.7266, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.1694, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.4402, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.0915, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.3291, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.2585, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.7465, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.4878, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.0256, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.7750, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.3660, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.5695, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3777, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.1243, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0540, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.6835, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.0779, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.5142, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.4257, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.4018, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.2535, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.3991, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.2616, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.2521, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.3951, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.1864, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.0283, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.3745, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.0432, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.5416, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.6442, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.1850, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.0754, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.0150, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.8655, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.5858, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.1316, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.0486, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.3006, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.1483, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.3625, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2826, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.1506, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.4906, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.1729, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.0912, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.1994, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.0993, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.2342, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(-0.0134, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(0.0461, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2376, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n",
      "tensor(-0.9552, device='cuda:0', grad_fn=<NegBackward>)\n",
      "tensor(0.2365, device='cuda:0', grad_fn=<NegBackward>)\n",
      "****\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-15943ebef1ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     last_al, last_cl, last_el = ppo_update(ppo_epochs, mini_batch_size, states, actions, \n\u001b[0;32m---> 54\u001b[0;31m                 log_probs, returns, advantages, values)\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-3aa6795e15ea>\u001b[0m in \u001b[0;36mppo_update\u001b[0;34m(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, values, clip_param)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mactor_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcritic_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcritic_loss\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mentropy_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnew_entropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mactor_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnew_entropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tyler/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tyler/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "state = envs.reset()\n",
    "update_iter = 0\n",
    "test_rewards\n",
    "\n",
    "while frame_idx < max_frames:\n",
    "    log_probs = []\n",
    "    values = []\n",
    "    rewards = []\n",
    "    masks = []\n",
    "    states = []\n",
    "    actions = []\n",
    "\n",
    "    \n",
    "    for step_index in range(num_steps):\n",
    "        # state is 16 x 4 because 16 envs\n",
    "        state = torch.FloatTensor(state).to(device)\n",
    "        states.append(state)\n",
    "        # dist and value each have 16 for all envs\n",
    "        dist, value = model(state)\n",
    "        \n",
    "        # have 16 actions\n",
    "        action = dist.sample()\n",
    "        actions.append(action)\n",
    "        next_state, reward, done, _ = envs.step(action.cpu().numpy())\n",
    "        log_prob = dist.log_prob(action)\n",
    "\n",
    "        log_probs.append(log_prob)\n",
    "        values.append(value)\n",
    "        # there are 16 rewards. Need to make it 16x1. Same for masks\n",
    "        rewards.append(torch.FloatTensor(reward).unsqueeze(1).to(device))\n",
    "        masks.append(torch.FloatTensor(1 - done).unsqueeze(1).to(device))\n",
    "                \n",
    "        state = next_state\n",
    "        frame_idx += 1\n",
    "        \n",
    "            \n",
    "        if frame_idx % save_every_update == 0:\n",
    "            test_rewards.append(np.mean([test_env() for _ in range(10)]))\n",
    "            plot(frame_idx, test_rewards)\n",
    "\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    _, next_value = model(next_state)\n",
    "    returns = compute_gae(next_value, rewards, masks, values)\n",
    "    \n",
    "    log_probs = torch.cat(log_probs).unsqueeze(1).to(device)\n",
    "    returns = torch.cat(returns).detach().to(device)\n",
    "    values = torch.cat(values).to(device)\n",
    "    advantages = returns - values\n",
    "    advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-5)\n",
    "    actions   = torch.cat(actions).unsqueeze(1).to(device)\n",
    "    states = torch.cat(states).to(device)\n",
    "                        \n",
    "    last_al, last_cl, last_el = ppo_update(ppo_epochs, mini_batch_size, states, actions, \n",
    "                log_probs, returns, advantages, values)\n",
    "    \n",
    "            \n",
    "    update_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
