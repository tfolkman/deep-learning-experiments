{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/tyler/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from comet_ml import Experiment\n",
    "\n",
    "import os\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "from gym.spaces.box import Box\n",
    "\n",
    "from baselines import bench\n",
    "from baselines.common.atari_wrappers import make_atari, wrap_deepmind\n",
    "from baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_envs = 8\n",
    "lr               = 2.5e-4\n",
    "num_steps        = 128\n",
    "mini_batch_size  = 32\n",
    "ppo_epochs       = 4\n",
    "save_every_update = 500\n",
    "gamma = 0.99\n",
    "tau = 0.95\n",
    "critic_weight = 0.5\n",
    "entropy_weight = 0.01\n",
    "clip_param = 0.1\n",
    "max_frames  = 5000\n",
    "\n",
    "\n",
    "render = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(env_id, seed, rank):\n",
    "    def _thunk():\n",
    "        if env_id.startswith(\"dm\"):\n",
    "            _, domain, task = env_id.split('.')\n",
    "            env = dm_control2gym.make(domain_name=domain, task_name=task)\n",
    "        else:\n",
    "            env = gym.make(env_id)\n",
    "        is_atari = hasattr(gym.envs, 'atari') and isinstance(\n",
    "            env.unwrapped, gym.envs.atari.atari_env.AtariEnv)\n",
    "        if is_atari:\n",
    "            # Does some pre-processing that affects pong\n",
    "            # 1) Samples initial states by taking random number of no-ops\n",
    "            #    on reset (at most 30)\n",
    "            # 2) Returns only every 4th frame\n",
    "            env = make_atari(env_id)\n",
    "        env.seed(seed + rank)\n",
    "\n",
    "\n",
    "        if is_atari:\n",
    "            # Does some pre-processing that affects pong\n",
    "            # 1) Make end-of-life == end-of-episode, but only reset on true game over\n",
    "            # 2) Warp frames to 84x84\n",
    "            # 3) Stack 4 frames\n",
    "            # 4) Scale the image by dividing by 255\n",
    "            env = wrap_deepmind(env, frame_stack=True, scale=True)\n",
    "\n",
    "        return env\n",
    "\n",
    "    return _thunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-5:\n",
      "Process Process-7:\n",
      "Process Process-2:\n",
      "Process Process-8:\n",
      "Process Process-1:\n",
      "Process Process-3:\n",
      "Process Process-4:\n",
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from common.multiprocessing_env import SubprocVecEnv\n",
    "\n",
    "env_name = \"CartPole-v0\"\n",
    "seed = 42\n",
    "\n",
    "\n",
    "envs = [make_env(env_name, seed, i)\n",
    "        for i in range(num_envs)]\n",
    "\n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_normc_(weight, gain=1):\n",
    "    weight.normal_(0, 1)\n",
    "    weight *= gain / torch.sqrt(weight.pow(2).sum(1, keepdim=True))\n",
    "    \n",
    "def init(module, weight_init, bias_init, gain=1):\n",
    "    weight_init(module.weight.data, gain=gain)\n",
    "    bias_init(module.bias.data)\n",
    "    return module\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        init_ = lambda m: init(m,\n",
    "              init_normc_,\n",
    "              lambda x: nn.init.constant_(x, 0))\n",
    "\n",
    "        self.actor = nn.Sequential(\n",
    "            init_(nn.Linear(num_inputs, 64)),\n",
    "            nn.Tanh(),\n",
    "            init_(nn.Linear(64, 64)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.critic = nn.Sequential(\n",
    "            init_(nn.Linear(num_inputs, 64)),\n",
    "            nn.Tanh(),\n",
    "            init_(nn.Linear(64, 64)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.critic_linear = init_(nn.Linear(64, 1))\n",
    "        self.actor_linear   = init_(nn.Linear(64, num_outputs))\n",
    "                         \n",
    "    def forward(self, x):\n",
    "        value = self.critic_linear(self.critic(x))\n",
    "        softs = F.softmax(self.actor_linear(self.actor(x)), dim=1)\n",
    "        dist = Categorical(softs)\n",
    "        return dist, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "    \n",
    "def test_env(vis=False):\n",
    "    state = env.reset()\n",
    "    if vis: env.render()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        next_state, reward, done, _ = env.step(dist.sample().cpu().numpy()[0])\n",
    "        state = next_state\n",
    "        if vis: env.render()\n",
    "        total_reward += reward\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gae(next_value, rewards, masks, values, gamma=gamma, tau=tau):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outputs = envs.action_space.n\n",
    "\n",
    "model = ActorCritic(4, num_outputs).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, eps=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx    = 0\n",
    "test_rewards = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important\n",
    "\n",
    "With GAE: GAE advantage just used for actor loss. Discounted returns used for critic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## grab random values for each batch\n",
    "def ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantage, values):\n",
    "    batch_size = states.size(0)\n",
    "    sampler = BatchSampler(SubsetRandomSampler(range(batch_size)), \n",
    "                           batch_size // mini_batch_size, \n",
    "                           drop_last=False)\n",
    "    for rand_ids in sampler:\n",
    "        yield states[rand_ids, :], actions[rand_ids, :], log_probs[rand_ids, :], returns[rand_ids, :], advantage[rand_ids, :], values[rand_ids, :]\n",
    "        \n",
    "        \n",
    "def ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, values, clip_param=clip_param):\n",
    "    for _ in range(ppo_epochs):\n",
    "        for s, act, lp, r, adv, v in ppo_iter(mini_batch_size, states, actions, log_probs,\n",
    "                                                                       returns, advantages, values):\n",
    "            \n",
    "            \n",
    "            new_dist, new_value = model(s)\n",
    "            new_entropy = new_dist.entropy().mean()\n",
    "            new_log_prob = new_dist.log_prob(act)\n",
    "            ratio = torch.exp(new_log_prob - lp)\n",
    "            surr1 = ratio * adv\n",
    "            surr2 = torch.clamp(ratio, 1.0 - clip_param, 1.0 + clip_param) * adv\n",
    "            #actor_loss = - torch.min(surr1, surr2).mean()\n",
    "            actor_loss = -(lp * adv.detach()).mean()\n",
    "            critic_loss = F.mse_loss(r,new_value)\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = (actor_loss + critic_weight * critic_loss - entropy_weight * new_entropy)\n",
    "            loss.backward(retain_graph=True)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "    return actor_loss, critic_loss, -new_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAE/CAYAAABW/Dj8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nG2OMT1igG2OMT/w/c1RCZeZdBZ8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-40997486b5b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     last_al, last_cl, last_el = ppo_update(ppo_epochs, mini_batch_size, states, actions, \n\u001b[0;32m---> 55\u001b[0;31m                 log_probs, returns, advantages, values)\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-4c5c90fe3dcf>\u001b[0m in \u001b[0;36mppo_update\u001b[0;34m(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, values, clip_param)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mactor_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcritic_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcritic_loss\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mentropy_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnew_entropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tyler/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tyler/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "state = envs.reset()\n",
    "update_iter = 0\n",
    "test_rewards\n",
    "\n",
    "while frame_idx < max_frames:\n",
    "    log_probs = []\n",
    "    values = []\n",
    "    rewards = []\n",
    "    masks = []\n",
    "    states = []\n",
    "    actions = []\n",
    "\n",
    "    \n",
    "    for step_index in range(num_steps):\n",
    "        # state is 16 x 4 because 16 envs\n",
    "        state = torch.FloatTensor(state).to(device)\n",
    "        states.append(state)\n",
    "        # dist and value each have 16 for all envs\n",
    "        dist, value = model(state)\n",
    "        \n",
    "        # have 16 actions\n",
    "        action = dist.sample()\n",
    "        actions.append(action)\n",
    "        next_state, reward, done, _ = envs.step(action.cpu().numpy())\n",
    "        \n",
    "        log_prob = dist.log_prob(action)\n",
    "\n",
    "        log_probs.append(log_prob)\n",
    "        values.append(value)\n",
    "        # there are 16 rewards. Need to make it 16x1. Same for masks\n",
    "        rewards.append(torch.FloatTensor(reward).unsqueeze(1).to(device))\n",
    "        masks.append(torch.FloatTensor(1 - done).unsqueeze(1).to(device))\n",
    "                \n",
    "        state = next_state\n",
    "        frame_idx += 1\n",
    "        \n",
    "            \n",
    "        if frame_idx % save_every_update == 0:\n",
    "            test_rewards.append(np.mean([test_env() for _ in range(10)]))\n",
    "            plot(frame_idx, test_rewards)\n",
    "\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    _, next_value = model(next_state)\n",
    "    returns = compute_gae(next_value, rewards, masks, values)\n",
    "    \n",
    "    log_probs = torch.cat(log_probs).unsqueeze(1).to(device)\n",
    "    returns = torch.cat(returns).detach().to(device)\n",
    "    values = torch.cat(values).to(device)\n",
    "    advantages = returns - values\n",
    "    advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-5)\n",
    "    actions   = torch.cat(actions).unsqueeze(1).to(device)\n",
    "    states = torch.cat(states).to(device)\n",
    "                        \n",
    "    last_al, last_cl, last_el = ppo_update(ppo_epochs, mini_batch_size, states, actions, \n",
    "                log_probs, returns, advantages, values)\n",
    "    \n",
    "            \n",
    "    update_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
