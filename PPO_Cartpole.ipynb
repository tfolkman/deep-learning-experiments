{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/tyler/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from comet_ml import Experiment\n",
    "\n",
    "import os\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "from gym.spaces.box import Box\n",
    "\n",
    "from baselines import bench\n",
    "from baselines.common.atari_wrappers import make_atari, wrap_deepmind\n",
    "from baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_envs = 8\n",
    "lr               = 2.5e-4\n",
    "num_steps        = 20\n",
    "mini_batch_size  = 5\n",
    "ppo_epochs       = 4\n",
    "save_every_update = 50\n",
    "gamma = 0.99\n",
    "tau = 0.95\n",
    "critic_weight = 1.0\n",
    "entropy_weight = 0.01\n",
    "clip_param = 0.1\n",
    "max_frames  = 5000\n",
    "\n",
    "\n",
    "render = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(env_id, seed, rank):\n",
    "    def _thunk():\n",
    "        if env_id.startswith(\"dm\"):\n",
    "            _, domain, task = env_id.split('.')\n",
    "            env = dm_control2gym.make(domain_name=domain, task_name=task)\n",
    "        else:\n",
    "            env = gym.make(env_id)\n",
    "        is_atari = hasattr(gym.envs, 'atari') and isinstance(\n",
    "            env.unwrapped, gym.envs.atari.atari_env.AtariEnv)\n",
    "        if is_atari:\n",
    "            # Does some pre-processing that affects pong\n",
    "            # 1) Samples initial states by taking random number of no-ops\n",
    "            #    on reset (at most 30)\n",
    "            # 2) Returns only every 4th frame\n",
    "            env = make_atari(env_id)\n",
    "        env.seed(seed + rank)\n",
    "\n",
    "\n",
    "        if is_atari:\n",
    "            # Does some pre-processing that affects pong\n",
    "            # 1) Make end-of-life == end-of-episode, but only reset on true game over\n",
    "            # 2) Warp frames to 84x84\n",
    "            # 3) Stack 4 frames\n",
    "            # 4) Scale the image by dividing by 255\n",
    "            env = wrap_deepmind(env, frame_stack=True, scale=True)\n",
    "\n",
    "        return env\n",
    "\n",
    "    return _thunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-4:\n",
      "Process Process-1:\n",
      "Process Process-2:\n",
      "Process Process-6:\n",
      "Process Process-5:\n",
      "Process Process-7:\n",
      "Process Process-8:\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/git_projects/deep-learning-experiments/common/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/tyler/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from common.multiprocessing_env import SubprocVecEnv\n",
    "\n",
    "env_name = \"CartPole-v0\"\n",
    "seed = 42\n",
    "\n",
    "\n",
    "envs = [make_env(env_name, seed, i)\n",
    "        for i in range(num_envs)]\n",
    "\n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_normc_(weight, gain=1):\n",
    "    weight.normal_(0, 1)\n",
    "    weight *= gain / torch.sqrt(weight.pow(2).sum(1, keepdim=True))\n",
    "    \n",
    "def init(module, weight_init, bias_init, gain=1):\n",
    "    weight_init(module.weight.data, gain=gain)\n",
    "    bias_init(module.bias.data)\n",
    "    return module\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        init_ = lambda m: init(m,\n",
    "              init_normc_,\n",
    "              lambda x: nn.init.constant_(x, 0))\n",
    "\n",
    "        self.actor = nn.Sequential(\n",
    "            init_(nn.Linear(num_inputs, 64)),\n",
    "            nn.Tanh(),\n",
    "            init_(nn.Linear(64, 64)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.critic = nn.Sequential(\n",
    "            init_(nn.Linear(num_inputs, 64)),\n",
    "            nn.Tanh(),\n",
    "            init_(nn.Linear(64, 64)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.critic_linear = init_(nn.Linear(64, 1))\n",
    "        self.actor_linear   = init_(nn.Linear(64, num_outputs))\n",
    "                         \n",
    "    def forward(self, x):\n",
    "        value = self.critic_linear(self.critic(x))\n",
    "        softs = F.softmax(self.actor_linear(self.actor(x)), dim=1)\n",
    "        dist = Categorical(softs)\n",
    "        return dist, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "    \n",
    "def test_env(vis=False):\n",
    "    state = env.reset()\n",
    "    if vis: env.render()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        next_state, reward, done, _ = env.step(dist.sample().cpu().numpy()[0])\n",
    "        state = next_state\n",
    "        if vis: env.render()\n",
    "        total_reward += reward\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gae(next_value, rewards, masks, values, gamma=gamma, tau=tau):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outputs = envs.action_space.n\n",
    "\n",
    "model = ActorCritic(4, num_outputs).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, eps=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx    = 0\n",
    "test_rewards = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important\n",
    "\n",
    "With GAE: GAE advantage just used for actor loss. Discounted returns used for critic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## grab random values for each batch\n",
    "def ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantage, values):\n",
    "    batch_size = states.size(0)\n",
    "    sampler = BatchSampler(SubsetRandomSampler(range(batch_size)), \n",
    "                           mini_batch_size, \n",
    "                           drop_last=False)\n",
    "    for rand_ids in sampler:\n",
    "        yield states[rand_ids, :], actions[rand_ids, :], log_probs[rand_ids, :], returns[rand_ids, :], advantage[rand_ids, :], values[rand_ids, :]\n",
    "        \n",
    "        \n",
    "def ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, values, clip_param=clip_param):\n",
    "    for _ in range(ppo_epochs):\n",
    "        for s, act, lp, r, adv, v in ppo_iter(mini_batch_size, states, actions, log_probs,\n",
    "                                                                       returns, advantages, values):\n",
    "            \n",
    "            act = act.squeeze(1)\n",
    "            lp = lp.squeeze(1)\n",
    "            adv = adv.squeeze(1)\n",
    "            \n",
    "            new_dist, new_value = model(s)\n",
    "            new_entropy = new_dist.entropy().mean()\n",
    "            new_log_prob = new_dist.log_prob(act)            \n",
    "            ratio = torch.exp(new_log_prob - lp)\n",
    "            \n",
    "            surr1 = ratio * adv\n",
    "            surr2 = torch.clamp(ratio, 1.0 - clip_param,\n",
    "                                           1.0 + clip_param) * adv\n",
    "            \n",
    "            actor_loss = -torch.min(surr1, surr2).mean()\n",
    "            critic_loss = F.mse_loss(r,new_value)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = (actor_loss + critic_weight * critic_loss - entropy_weight * new_entropy)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "    return actor_loss, critic_loss, -new_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAE/CAYAAACNR5LeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nu0QAl9srAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-15943ebef1ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     last_al, last_cl, last_el = ppo_update(ppo_epochs, mini_batch_size, states, actions, \n\u001b[0;32m---> 54\u001b[0;31m                 log_probs, returns, advantages, values)\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-37e1e93f94b2>\u001b[0m in \u001b[0;36mppo_update\u001b[0;34m(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, values, clip_param)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mactor_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcritic_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcritic_loss\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mentropy_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnew_entropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mactor_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnew_entropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tyler/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tyler/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "state = envs.reset()\n",
    "update_iter = 0\n",
    "test_rewards\n",
    "\n",
    "while frame_idx < max_frames:\n",
    "    log_probs = []\n",
    "    values = []\n",
    "    rewards = []\n",
    "    masks = []\n",
    "    states = []\n",
    "    actions = []\n",
    "\n",
    "    \n",
    "    for step_index in range(num_steps):\n",
    "        # state is 16 x 4 because 16 envs\n",
    "        state = torch.FloatTensor(state).to(device)\n",
    "        states.append(state)\n",
    "        # dist and value each have 16 for all envs\n",
    "        dist, value = model(state)\n",
    "        \n",
    "        # have 16 actions\n",
    "        action = dist.sample()\n",
    "        actions.append(action)\n",
    "        next_state, reward, done, _ = envs.step(action.cpu().numpy())\n",
    "        log_prob = dist.log_prob(action)\n",
    "\n",
    "        log_probs.append(log_prob)\n",
    "        values.append(value)\n",
    "        # there are 16 rewards. Need to make it 16x1. Same for masks\n",
    "        rewards.append(torch.FloatTensor(reward).unsqueeze(1).to(device))\n",
    "        masks.append(torch.FloatTensor(1 - done).unsqueeze(1).to(device))\n",
    "                \n",
    "        state = next_state\n",
    "        frame_idx += 1\n",
    "        \n",
    "            \n",
    "        if frame_idx % save_every_update == 0:\n",
    "            test_rewards.append(np.mean([test_env() for _ in range(10)]))\n",
    "            plot(frame_idx, test_rewards)\n",
    "\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    _, next_value = model(next_state)\n",
    "    returns = compute_gae(next_value, rewards, masks, values)\n",
    "    \n",
    "    log_probs = torch.cat(log_probs).unsqueeze(1).to(device)\n",
    "    returns = torch.cat(returns).detach().to(device)\n",
    "    values = torch.cat(values).to(device)\n",
    "    advantages = returns - values\n",
    "    advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-5)\n",
    "    actions   = torch.cat(actions).unsqueeze(1).to(device)\n",
    "    states = torch.cat(states).to(device)\n",
    "                        \n",
    "    last_al, last_cl, last_el = ppo_update(ppo_epochs, mini_batch_size, states, actions, \n",
    "                log_probs, returns, advantages, values)\n",
    "    \n",
    "            \n",
    "    update_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
